{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import spearmanr\n",
    "import ast\n",
    "from scipy.stats import kstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>Imbalance %</th>\n",
       "      <th>Model name</th>\n",
       "      <th>Model ID</th>\n",
       "      <th>id</th>\n",
       "      <th>words_sentence</th>\n",
       "      <th>lime_sentence</th>\n",
       "      <th>words_word</th>\n",
       "      <th>lime_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>LLama</td>\n",
       "      <td>10</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['there', 'may', 'not', 'be', 'a', 'critic', '...</td>\n",
       "      <td>[-0.022934971744675903, -0.0011958517663429719...</td>\n",
       "      <td>['a' 'about' 'accidental' 'act' 'action' 'affe...</td>\n",
       "      <td>[4.33616739313076e-05, -0.003697329228902472, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>10</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['there', 'may', 'not', 'be', 'a', 'critic', '...</td>\n",
       "      <td>[-0.025988159852367843, 6.581122178263225e-05,...</td>\n",
       "      <td>['a' 'about' 'accidental' 'act' 'action' 'affe...</td>\n",
       "      <td>[0.0014720104444310655, -0.0034905926641814796...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>imbalanced</td>\n",
       "      <td>10</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['there', 'may', 'not', 'be', 'a', 'critic', '...</td>\n",
       "      <td>[-0.0025273509423874344, 0.0014477108266709824...</td>\n",
       "      <td>['a' 'about' 'accidental' 'act' 'action' 'affe...</td>\n",
       "      <td>[-0.00017893744925643828, 0.000100026422368737...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>LLama</td>\n",
       "      <td>10</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['there', 'may', 'not', 'be', 'a', 'critic', '...</td>\n",
       "      <td>[-0.019187657083878585, 0.0007502100698324174,...</td>\n",
       "      <td>['a' 'about' 'accidental' 'act' 'action' 'affe...</td>\n",
       "      <td>[0.0004965719029304788, -0.005638696011876343,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>10</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['there', 'may', 'not', 'be', 'a', 'critic', '...</td>\n",
       "      <td>[-0.02249236333856587, 0.0013970486623292872, ...</td>\n",
       "      <td>['a' 'about' 'accidental' 'act' 'action' 'affe...</td>\n",
       "      <td>[0.002134552624563309, -0.005568715394313648, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>['post', 'chasing', 'amy', 'a', 'slew', 'of', ...</td>\n",
       "      <td>[-0.006673409508617923, -0.003302518305947108,...</td>\n",
       "      <td>['a' 'about' 'absolutely' 'actress' 'affection...</td>\n",
       "      <td>[0.007313659886995239, -0.03943056670312839, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>['post', 'chasing', 'amy', 'a', 'slew', 'of', ...</td>\n",
       "      <td>[-0.002011967401941093, 0.003023487946904732, ...</td>\n",
       "      <td>['a' 'about' 'absolutely' 'actress' 'affection...</td>\n",
       "      <td>[0.001734781503550134, -0.022458994400458576, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>Translation</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>['post', 'chasing', 'amy', 'a', 'slew', 'of', ...</td>\n",
       "      <td>[-0.006630525803076841, -0.0011548571634200369...</td>\n",
       "      <td>['a' 'about' 'absolutely' 'actress' 'affection...</td>\n",
       "      <td>[0.007536974074509293, -0.03649603137169283, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>imbalanced</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>['post', 'chasing', 'amy', 'a', 'slew', 'of', ...</td>\n",
       "      <td>[-0.005686366598732487, -0.0012348522757685751...</td>\n",
       "      <td>['a' 'about' 'absolutely' 'actress' 'affection...</td>\n",
       "      <td>[-0.0025714797093108065, -0.01913111031902743,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>['post', 'chasing', 'amy', 'a', 'slew', 'of', ...</td>\n",
       "      <td>[-0.015339951746953353, -0.0017182704121351954...</td>\n",
       "      <td>['a' 'about' 'absolutely' 'actress' 'affection...</td>\n",
       "      <td>[0.002908738636550806, -0.03219416853269157, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3120 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Balancing method Imbalance % Model name Model ID  id                                     words_sentence                                      lime_sentence                                         words_word                                          lime_word\n",
       "2360                LLama          10        SVM        0   0  ['there', 'may', 'not', 'be', 'a', 'critic', '...  [-0.022934971744675903, -0.0011958517663429719...  ['a' 'about' 'accidental' 'act' 'action' 'affe...  [4.33616739313076e-05, -0.003697329228902472, ...\n",
       "240         LLama_complex          10        SVM        0   0  ['there', 'may', 'not', 'be', 'a', 'critic', '...  [-0.025988159852367843, 6.581122178263225e-05,...  ['a' 'about' 'accidental' 'act' 'action' 'affe...  [0.0014720104444310655, -0.0034905926641814796...\n",
       "1200           imbalanced          10        SVM        0   0  ['there', 'may', 'not', 'be', 'a', 'critic', '...  [-0.0025273509423874344, 0.0014477108266709824...  ['a' 'about' 'accidental' 'act' 'action' 'affe...  [-0.00017893744925643828, 0.000100026422368737...\n",
       "2120                LLama          10        SVM        1   0  ['there', 'may', 'not', 'be', 'a', 'critic', '...  [-0.019187657083878585, 0.0007502100698324174,...  ['a' 'about' 'accidental' 'act' 'action' 'affe...  [0.0004965719029304788, -0.005638696011876343,...\n",
       "840         LLama_complex          10        SVM        1   0  ['there', 'may', 'not', 'be', 'a', 'critic', '...  [-0.02249236333856587, 0.0013970486623292872, ...  ['a' 'about' 'accidental' 'act' 'action' 'affe...  [0.002134552624563309, -0.005568715394313648, ...\n",
       "...                   ...         ...        ...      ...  ..                                                ...                                                ...                                                ...                                                ...\n",
       "1879        Summarization          50        SVM        4  39  ['post', 'chasing', 'amy', 'a', 'slew', 'of', ...  [-0.006673409508617923, -0.003302518305947108,...  ['a' 'about' 'absolutely' 'actress' 'affection...  [0.007313659886995239, -0.03943056670312839, 0...\n",
       "2839  Synonym replacement          50        SVM        4  39  ['post', 'chasing', 'amy', 'a', 'slew', 'of', ...  [-0.002011967401941093, 0.003023487946904732, ...  ['a' 'about' 'absolutely' 'actress' 'affection...  [0.001734781503550134, -0.022458994400458576, ...\n",
       "2799          Translation          50        SVM        4  39  ['post', 'chasing', 'amy', 'a', 'slew', 'of', ...  [-0.006630525803076841, -0.0011548571634200369...  ['a' 'about' 'absolutely' 'actress' 'affection...  [0.007536974074509293, -0.03649603137169283, 0...\n",
       "1679           imbalanced          50        SVM        4  39  ['post', 'chasing', 'amy', 'a', 'slew', 'of', ...  [-0.005686366598732487, -0.0012348522757685751...  ['a' 'about' 'absolutely' 'actress' 'affection...  [-0.0025714797093108065, -0.01913111031902743,...\n",
       "239            paraphrase          50        SVM        4  39  ['post', 'chasing', 'amy', 'a', 'slew', 'of', ...  [-0.015339951746953353, -0.0017182704121351954...  ['a' 'about' 'absolutely' 'actress' 'affection...  [0.002908738636550806, -0.03219416853269157, 0...\n",
       "\n",
       "[3120 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method used to decode filename of model into balancing method, imbalance %, model name, and model id returned in an array\n",
    "def get_method_and_percentage(name):\n",
    "    string = \"_\".join(name.split(\"_\")[:-1])\n",
    "    percentage = \"\"\n",
    "    perc = 0\n",
    "    for i in range(len(string)):\n",
    "        if string[i].isdigit():\n",
    "            perc = i\n",
    "            percentage += string[i]\n",
    "        elif perc>0:\n",
    "            break\n",
    "    perc+=2 if len(percentage)>0 else 0\n",
    "    method = \"\"\n",
    "    for i in range(perc, len(string)):\n",
    "        if string[i].isdigit():\n",
    "            model_id = string[i]\n",
    "        else:\n",
    "            method += string[i]\n",
    "    method = \"_\".join(method.split(\"_\")[:-1])\n",
    "    model = name.split(\"_\")[-1][:-4]\n",
    "    return [method, percentage, model, model_id]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Maciek\\Documents\\Studia\\Magisterka\\Results\\XAI_results_final_SVM.csv\")\n",
    "# for i in range(2,5):\n",
    "#     df = pd.concat([df, pd.read_csv(f\"XAI_results{i}.csv\")])\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "name = pd.DataFrame(list(df[\"model\"].map(lambda x:get_method_and_percentage(x))))\n",
    "name.columns = [\"Balancing method\", \"Imbalance %\", \"Model name\", \"Model ID\"]\n",
    "df = pd.concat([name, df[df.columns[2:]]], axis=1)\n",
    "df = df.sort_values([\"id\", \"Imbalance %\", \"Model ID\", \"Balancing method\", \"Model name\"])\n",
    "df.columns = [str(col).replace(\"eval_\", \"\") for col in df.columns]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>Imbalance %</th>\n",
       "      <th>Model name</th>\n",
       "      <th>Model ID</th>\n",
       "      <th>id</th>\n",
       "      <th>words_sentence</th>\n",
       "      <th>lime_sentence</th>\n",
       "      <th>words_word</th>\n",
       "      <th>lime_word</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>['it', 's', 'a', 'good', 'thing', 'most', 'ani...</td>\n",
       "      <td>[0.031849191768026544, -0.0011960557031903058,...</td>\n",
       "      <td>['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...</td>\n",
       "      <td>[-0.005298016896720529, -0.0042918087701462075...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>imbalanced</td>\n",
       "      <td>20</td>\n",
       "      <td>SVM</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>['it', 's', 'a', 'good', 'thing', 'most', 'ani...</td>\n",
       "      <td>[0.004089166517551643, 0.0005204621505550933, ...</td>\n",
       "      <td>['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...</td>\n",
       "      <td>[-0.0018614625615115219, -0.002432307388459732...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>LLama</td>\n",
       "      <td>20</td>\n",
       "      <td>SVM</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>['it', 's', 'a', 'good', 'thing', 'most', 'ani...</td>\n",
       "      <td>[-0.013326476380173969, 0.0009208688441119695,...</td>\n",
       "      <td>['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...</td>\n",
       "      <td>[-0.003498334413600534, 0.0014995137338869602,...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>20</td>\n",
       "      <td>SVM</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>['it', 's', 'a', 'good', 'thing', 'most', 'ani...</td>\n",
       "      <td>[-0.020935154867176193, 0.0006985026374140209,...</td>\n",
       "      <td>['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...</td>\n",
       "      <td>[-0.002019185736443124, -0.0003187892320295745...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>imbalanced</td>\n",
       "      <td>20</td>\n",
       "      <td>SVM</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>['it', 's', 'a', 'good', 'thing', 'most', 'ani...</td>\n",
       "      <td>[-0.003915706927809466, 0.0003211244183558381,...</td>\n",
       "      <td>['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...</td>\n",
       "      <td>[-0.005498296704163613, 0.0024422985880980567,...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>['star', 'wars', 'episode', 'i', 'the', 'phant...</td>\n",
       "      <td>[0.029458801436211254, 0.0525624184966656, 0.0...</td>\n",
       "      <td>['131' '1999' '20th' 'a' 'about' 'abysmally' '...</td>\n",
       "      <td>[0, 0.017576758418209656, -0.00651183977602794...</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>['star', 'wars', 'episode', 'i', 'the', 'phant...</td>\n",
       "      <td>[0.028990856786910855, 0.0385605498065149, 0.0...</td>\n",
       "      <td>['131' '1999' '20th' 'a' 'about' 'abysmally' '...</td>\n",
       "      <td>[-0.006693510934525654, 0.017975737634445158, ...</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>Translation</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>['star', 'wars', 'episode', 'i', 'the', 'phant...</td>\n",
       "      <td>[0.019648312890075143, 0.04436647845318184, 0....</td>\n",
       "      <td>['131' '1999' '20th' 'a' 'about' 'abysmally' '...</td>\n",
       "      <td>[0.004627736361521242, 0.020177244752031292, -...</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Contextual_word_embedding</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>['star', 'wars', 'episode', 'i', 'the', 'phant...</td>\n",
       "      <td>[0.03263642461234773, 0.03683442746466363, -0....</td>\n",
       "      <td>['131' '1999' '20th' 'a' 'about' 'abysmally' '...</td>\n",
       "      <td>[-0.006845332364972416, 0.017676679227794465, ...</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>imbalanced</td>\n",
       "      <td>50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>['star', 'wars', 'episode', 'i', 'the', 'phant...</td>\n",
       "      <td>[0.022589494650761228, 0.024769692843867486, 0...</td>\n",
       "      <td>['131' '1999' '20th' 'a' 'about' 'abysmally' '...</td>\n",
       "      <td>[-0.0077960268101165756, 0.005752728768266125,...</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3120 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Balancing method Imbalance % Model name Model ID  id                                     words_sentence                                      lime_sentence                                         words_word                                          lime_word  test\n",
       "1884                 paraphrase          50        SVM        0   4  ['it', 's', 'a', 'good', 'thing', 'most', 'ani...  [0.031849191768026544, -0.0011960557031903058,...  ['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...  [-0.005298016896720529, -0.0042918087701462075...   227\n",
       "1444                 imbalanced          20        SVM        2   4  ['it', 's', 'a', 'good', 'thing', 'most', 'ani...  [0.004089166517551643, 0.0005204621505550933, ...  ['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...  [-0.0018614625615115219, -0.002432307388459732...   227\n",
       "2724                      LLama          20        SVM        3   4  ['it', 's', 'a', 'good', 'thing', 'most', 'ani...  [-0.013326476380173969, 0.0009208688441119695,...  ['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...  [-0.003498334413600534, 0.0014995137338869602,...   227\n",
       "1604              LLama_complex          20        SVM        3   4  ['it', 's', 'a', 'good', 'thing', 'most', 'ani...  [-0.020935154867176193, 0.0006985026374140209,...  ['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...  [-0.002019185736443124, -0.0003187892320295745...   227\n",
       "564                  imbalanced          20        SVM        3   4  ['it', 's', 'a', 'good', 'thing', 'most', 'ani...  [-0.003915706927809466, 0.0003211244183558381,...  ['31st' 'a' 'about' 'action' 'aliens' 'all' 'a...  [-0.005498296704163613, 0.0024422985880980567,...   227\n",
       "...                         ...         ...        ...      ...  ..                                                ...                                                ...                                                ...                                                ...   ...\n",
       "946               Summarization          50        SVM        2  26  ['star', 'wars', 'episode', 'i', 'the', 'phant...  [0.029458801436211254, 0.0525624184966656, 0.0...  ['131' '1999' '20th' 'a' 'about' 'abysmally' '...  [0, 0.017576758418209656, -0.00651183977602794...  1503\n",
       "466         Synonym replacement          50        SVM        2  26  ['star', 'wars', 'episode', 'i', 'the', 'phant...  [0.028990856786910855, 0.0385605498065149, 0.0...  ['131' '1999' '20th' 'a' 'about' 'abysmally' '...  [-0.006693510934525654, 0.017975737634445158, ...  1503\n",
       "1546                Translation          50        SVM        2  26  ['star', 'wars', 'episode', 'i', 'the', 'phant...  [0.019648312890075143, 0.04436647845318184, 0....  ['131' '1999' '20th' 'a' 'about' 'abysmally' '...  [0.004627736361521242, 0.020177244752031292, -...  1503\n",
       "986   Contextual_word_embedding          50        SVM        2  26  ['star', 'wars', 'episode', 'i', 'the', 'phant...  [0.03263642461234773, 0.03683442746466363, -0....  ['131' '1999' '20th' 'a' 'about' 'abysmally' '...  [-0.006845332364972416, 0.017676679227794465, ...  1503\n",
       "1666                 imbalanced          50        SVM        4  26  ['star', 'wars', 'episode', 'i', 'the', 'phant...  [0.022589494650761228, 0.024769692843867486, 0...  ['131' '1999' '20th' 'a' 'about' 'abysmally' '...  [-0.0077960268101165756, 0.005752728768266125,...  1503\n",
       "\n",
       "[3120 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tm = df\n",
    "df_tm[\"test\"]=df[\"words_sentence\"].apply(lambda x:len(ast.literal_eval(x)))\n",
    "df_tm.sort_values([\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________ original _________________\n",
      "\u001b[38;2;231;255;231m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;245;255;245m\u001b[48;2;0;0;0mgood \u001b[0m\u001b[38;2;255;244;244m\u001b[48;2;0;0;0mthing \u001b[0m\u001b[38;2;223;255;223m\u001b[48;2;0;0;0mmost \u001b[0m\u001b[38;2;255;252;252m\u001b[48;2;0;0;0manimated \u001b[0m\u001b[38;2;169;255;169m\u001b[48;2;0;0;0msci \u001b[0m\u001b[38;2;176;255;176m\u001b[48;2;0;0;0mfi \u001b[0m\u001b[38;2;234;255;234m\u001b[48;2;0;0;0mmovies \u001b[0m\u001b[38;2;255;240;240m\u001b[48;2;0;0;0mcome \u001b[0m\u001b[38;2;237;255;237m\u001b[48;2;0;0;0mfrom \u001b[0m\u001b[38;2;255;240;240m\u001b[48;2;0;0;0mjapan \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0mbecause \u001b[0m\u001b[38;2;255;251;251m\u001b[48;2;0;0;0mtitan \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;243;255;243m\u001b[48;2;0;0;0me \u001b[0m\u001b[38;2;198;255;198m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;203;255;203m\u001b[48;2;0;0;0mproof \u001b[0m\u001b[38;2;255;225;225m\u001b[48;2;0;0;0mthat \u001b[0m\u001b[38;2;234;255;234m\u001b[48;2;0;0;0mhollywood \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0mdoes \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0mn \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mt \u001b[0m\u001b[38;2;255;201;201m\u001b[48;2;0;0;0mhave \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mclue \u001b[0m\n",
      "\u001b[38;2;255;244;244m\u001b[48;2;0;0;0mhow \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;105;105m\u001b[48;2;0;0;0mdo \u001b[0m\u001b[38;2;231;255;231m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0mi \u001b[0m\u001b[38;2;255;105;105m\u001b[48;2;0;0;0mdo \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0mn \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mt \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0mknow \u001b[0m\u001b[38;2;255;223;223m\u001b[48;2;0;0;0mwhat \u001b[0m\u001b[38;2;255;223;223m\u001b[48;2;0;0;0mthis \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0mfilm \u001b[0m\u001b[38;2;198;255;198m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;255;76;76m\u001b[48;2;0;0;0msupposed \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;215;215m\u001b[48;2;0;0;0mbe \u001b[0m\u001b[38;2;255;233;233m\u001b[48;2;0;0;0mabout \u001b[0m\u001b[38;2;237;255;237m\u001b[48;2;0;0;0mfrom \u001b[0m\u001b[38;2;255;223;223m\u001b[48;2;0;0;0mwhat \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0mi \u001b[0m\u001b[38;2;255;243;243m\u001b[48;2;0;0;0mcan \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mtell \u001b[0m\u001b[38;2;231;255;231m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;233;233m\u001b[48;2;0;0;0mabout \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;240;255;240m\u001b[48;2;0;0;0myoung \u001b[0m\u001b[38;2;221;255;221m\u001b[48;2;0;0;0mman \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0mnamed \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0mkale \u001b[0m\u001b[38;2;243;255;243m\u001b[48;2;0;0;0mwho \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;217;255;217m\u001b[48;2;0;0;0mone \u001b[0m\u001b[38;2;179;255;179m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\n",
      "\u001b[38;2;255;251;251m\u001b[48;2;0;0;0mlast \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0msurvivors \u001b[0m\u001b[38;2;179;255;179m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;255;226;226m\u001b[48;2;0;0;0mearth \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;201;201m\u001b[48;2;0;0;0mearly \u001b[0m\u001b[38;2;255;234;234m\u001b[48;2;0;0;0m31st \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0mcentury \u001b[0m\u001b[38;2;243;255;243m\u001b[48;2;0;0;0mwho \u001b[0m\u001b[38;2;243;255;243m\u001b[48;2;0;0;0munknowingly \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mpossesses \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;186;255;186m\u001b[48;2;0;0;0mkey \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;212;212m\u001b[48;2;0;0;0msaving \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0mre \u001b[0m\u001b[38;2;231;255;231m\u001b[48;2;0;0;0mgenerating \u001b[0m\u001b[38;2;255;223;223m\u001b[48;2;0;0;0mwhat \u001b[0m\u001b[38;2;198;255;198m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;255;226;226m\u001b[48;2;0;0;0mleft \u001b[0m\n",
      "\u001b[38;2;179;255;179m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;225;255;225m\u001b[48;2;0;0;0mhuman \u001b[0m\u001b[38;2;236;255;236m\u001b[48;2;0;0;0mrace \u001b[0m\u001b[38;2;255;225;225m\u001b[48;2;0;0;0mthat \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;203;255;203m\u001b[48;2;0;0;0mfine \u001b[0m\u001b[38;2;255;252;252m\u001b[48;2;0;0;0mpremise \u001b[0m\u001b[38;2;255;228;228m\u001b[48;2;0;0;0mfor \u001b[0m\u001b[38;2;255;228;228m\u001b[48;2;0;0;0man \u001b[0m\u001b[38;2;255;218;218m\u001b[48;2;0;0;0maction \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0mpacked \u001b[0m\u001b[38;2;169;255;169m\u001b[48;2;0;0;0msci \u001b[0m\u001b[38;2;176;255;176m\u001b[48;2;0;0;0mfi \u001b[0m\u001b[38;2;255;252;252m\u001b[48;2;0;0;0manimated \u001b[0m\u001b[38;2;255;203;203m\u001b[48;2;0;0;0mmovie \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0mbut \u001b[0m\u001b[38;2;255;158;158m\u001b[48;2;0;0;0mthere \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;114;114m\u001b[48;2;0;0;0mno \u001b[0m\u001b[38;2;239;255;239m\u001b[48;2;0;0;0mpayoff \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;205;205m\u001b[48;2;0;0;0mstory \u001b[0m\u001b[38;2;227;255;227m\u001b[48;2;0;0;0mtakes \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\n",
      "\u001b[38;2;255;209;209m\u001b[48;2;0;0;0mmain \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0mcharacters \u001b[0m\u001b[38;2;255;228;228m\u001b[48;2;0;0;0mall \u001b[0m\u001b[38;2;236;255;236m\u001b[48;2;0;0;0mover \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0mgalaxy \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mtheir \u001b[0m\u001b[38;2;238;255;238m\u001b[48;2;0;0;0msearch \u001b[0m\u001b[38;2;255;228;228m\u001b[48;2;0;0;0mfor \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;242;255;242m\u001b[48;2;0;0;0mlegendary \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mship \u001b[0m\u001b[38;2;255;225;225m\u001b[48;2;0;0;0mthat \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;233;255;233m\u001b[48;2;0;0;0mevil \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0mdredge \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0maliens \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mwant \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;224;255;224m\u001b[48;2;0;0;0mdestroy \u001b[0m\u001b[38;2;255;228;228m\u001b[48;2;0;0;0mfor \u001b[0m\u001b[38;2;255;114;114m\u001b[48;2;0;0;0mno \u001b[0m\n",
      "\u001b[38;2;255;220;220m\u001b[48;2;0;0;0mapparent \u001b[0m\u001b[38;2;255;180;180m\u001b[48;2;0;0;0mreason \u001b[0m\u001b[38;2;255;204;204m\u001b[48;2;0;0;0mso \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;217;255;217m\u001b[48;2;0;0;0mprocess \u001b[0m\u001b[38;2;238;255;238m\u001b[48;2;0;0;0mwe \u001b[0m\u001b[38;2;255;234;234m\u001b[48;2;0;0;0mget \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;255;251;251m\u001b[48;2;0;0;0mlot \u001b[0m\u001b[38;2;179;255;179m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mspaceship \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mfights \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mfistfights \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0mblaster \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mfights \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mmore \u001b[0m\u001b[38;2;255;228;228m\u001b[48;2;0;0;0mdouble \u001b[0m\u001b[38;2;241;255;241m\u001b[48;2;0;0;0mcrosses \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0mthan \u001b[0m\u001b[38;2;222;255;222m\u001b[48;2;0;0;0myou \u001b[0m\u001b[38;2;255;243;243m\u001b[48;2;0;0;0mcan \u001b[0m\n",
      "\u001b[38;2;255;240;240m\u001b[48;2;0;0;0mshake \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mstick \u001b[0m\u001b[38;2;255;223;223m\u001b[48;2;0;0;0mat \u001b[0m\u001b[38;2;255;158;158m\u001b[48;2;0;0;0mthere \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;204;204m\u001b[48;2;0;0;0mso \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0mmuch \u001b[0m\u001b[38;2;255;197;197m\u001b[48;2;0;0;0mpointless \u001b[0m\u001b[38;2;169;255;169m\u001b[48;2;0;0;0msci \u001b[0m\u001b[38;2;176;255;176m\u001b[48;2;0;0;0mfi \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0mbanterit \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mtoo \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0mmuch \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;226;255;226m\u001b[48;2;0;0;0mtake \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0mgalaxy \u001b[0m\u001b[38;2;255;220;220m\u001b[48;2;0;0;0mhere \u001b[0m\u001b[38;2;198;255;198m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;255;193;193m\u001b[48;2;0;0;0mtotal \u001b[0m\u001b[38;2;255;201;201m\u001b[48;2;0;0;0mrip \u001b[0m\u001b[38;2;255;211;211m\u001b[48;2;0;0;0moff \u001b[0m\u001b[38;2;179;255;179m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;221;255;221m\u001b[48;2;0;0;0mstar \u001b[0m\u001b[38;2;194;255;194m\u001b[48;2;0;0;0mwars \u001b[0m\n",
      "\u001b[38;2;255;236;236m\u001b[48;2;0;0;0muniverse \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0mcreators \u001b[0m\u001b[38;2;255;105;105m\u001b[48;2;0;0;0mdo \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0mn \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mt \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0mbother \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0mfilling \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;239;239m\u001b[48;2;0;0;0mbasic \u001b[0m\u001b[38;2;212;255;212m\u001b[48;2;0;0;0mdetails \u001b[0m\u001b[38;2;240;255;240m\u001b[48;2;0;0;0mwhich \u001b[0m\u001b[38;2;197;255;197m\u001b[48;2;0;0;0mmakes \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;205;205m\u001b[48;2;0;0;0mstory \u001b[0m\u001b[38;2;255;222;222m\u001b[48;2;0;0;0mconfusing \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0mcharacters \u001b[0m\u001b[38;2;242;255;242m\u001b[48;2;0;0;0munmotivated \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\n",
      "\u001b[38;2;249;255;249m\u001b[48;2;0;0;0msuperficial \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;161;161m\u001b[48;2;0;0;0mplot \u001b[0m\u001b[38;2;255;185;185m\u001b[48;2;0;0;0mjust \u001b[0m\u001b[38;2;255;227;227m\u001b[48;2;0;0;0mplain \u001b[0m\u001b[38;2;255;121;121m\u001b[48;2;0;0;0mboring \u001b[0m\u001b[38;2;212;255;212m\u001b[48;2;0;0;0mdespite \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;170;255;170m\u001b[48;2;0;0;0mfantastic \u001b[0m\u001b[38;2;181;255;181m\u001b[48;2;0;0;0manimation \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mspecial \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0meffects \u001b[0m\u001b[38;2;231;255;231m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;185;185m\u001b[48;2;0;0;0mjust \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0mnot \u001b[0m\u001b[38;2;255;228;228m\u001b[48;2;0;0;0man \u001b[0m\u001b[38;2;255;229;229m\u001b[48;2;0;0;0minteresting \u001b[0m\u001b[38;2;255;203;203m\u001b[48;2;0;0;0mmovie \u001b[0m"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________ LLama_complex _________________\n",
      "\u001b[38;2;255;191;191m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;255;245;245m\u001b[48;2;0;0;0mgood \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mthing \u001b[0m\u001b[38;2;241;255;241m\u001b[48;2;0;0;0mmost \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0manimated \u001b[0m\u001b[38;2;90;255;90m\u001b[48;2;0;0;0msci \u001b[0m\u001b[38;2;102;255;102m\u001b[48;2;0;0;0mfi \u001b[0m\u001b[38;2;242;255;242m\u001b[48;2;0;0;0mmovies \u001b[0m\u001b[38;2;255;241;241m\u001b[48;2;0;0;0mcome \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mfrom \u001b[0m\u001b[38;2;255;239;239m\u001b[48;2;0;0;0mjapan \u001b[0m\u001b[38;2;255;199;199m\u001b[48;2;0;0;0mbecause \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0mtitan \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0me \u001b[0m\u001b[38;2;177;255;177m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;241;255;241m\u001b[48;2;0;0;0mproof \u001b[0m\u001b[38;2;255;233;233m\u001b[48;2;0;0;0mthat \u001b[0m\u001b[38;2;255;233;233m\u001b[48;2;0;0;0mhollywood \u001b[0m\u001b[38;2;255;241;241m\u001b[48;2;0;0;0mdoes \u001b[0m\u001b[38;2;255;245;245m\u001b[48;2;0;0;0mn \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0mt \u001b[0m\u001b[38;2;255;191;191m\u001b[48;2;0;0;0mhave \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;232;255;232m\u001b[48;2;0;0;0mclue \u001b[0m\n",
      "\u001b[38;2;252;255;252m\u001b[48;2;0;0;0mhow \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;108;108m\u001b[48;2;0;0;0mdo \u001b[0m\u001b[38;2;255;191;191m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0mi \u001b[0m\u001b[38;2;255;108;108m\u001b[48;2;0;0;0mdo \u001b[0m\u001b[38;2;255;245;245m\u001b[48;2;0;0;0mn \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0mt \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mknow \u001b[0m\u001b[38;2;255;248;248m\u001b[48;2;0;0;0mwhat \u001b[0m\u001b[38;2;255;199;199m\u001b[48;2;0;0;0mthis \u001b[0m\u001b[38;2;240;255;240m\u001b[48;2;0;0;0mfilm \u001b[0m\u001b[38;2;177;255;177m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;255;193;193m\u001b[48;2;0;0;0msupposed \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;194;194m\u001b[48;2;0;0;0mbe \u001b[0m\u001b[38;2;255;184;184m\u001b[48;2;0;0;0mabout \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mfrom \u001b[0m\u001b[38;2;255;248;248m\u001b[48;2;0;0;0mwhat \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0mi \u001b[0m\u001b[38;2;255;227;227m\u001b[48;2;0;0;0mcan \u001b[0m\u001b[38;2;255;236;236m\u001b[48;2;0;0;0mtell \u001b[0m\u001b[38;2;255;191;191m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;184;184m\u001b[48;2;0;0;0mabout \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;223;255;223m\u001b[48;2;0;0;0myoung \u001b[0m\u001b[38;2;237;255;237m\u001b[48;2;0;0;0mman \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0mnamed \u001b[0m\u001b[38;2;255;252;252m\u001b[48;2;0;0;0mkale \u001b[0m\u001b[38;2;237;255;237m\u001b[48;2;0;0;0mwho \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;242;255;242m\u001b[48;2;0;0;0mone \u001b[0m\u001b[38;2;208;255;208m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\n",
      "\u001b[38;2;255;208;208m\u001b[48;2;0;0;0mlast \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0msurvivors \u001b[0m\u001b[38;2;208;255;208m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0mearth \u001b[0m\u001b[38;2;255;128;128m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;240;240m\u001b[48;2;0;0;0mearly \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0m31st \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0mcentury \u001b[0m\u001b[38;2;237;255;237m\u001b[48;2;0;0;0mwho \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0munknowingly \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mpossesses \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;231;255;231m\u001b[48;2;0;0;0mkey \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;223;223m\u001b[48;2;0;0;0msaving \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;255;242;242m\u001b[48;2;0;0;0mre \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0mgenerating \u001b[0m\u001b[38;2;255;248;248m\u001b[48;2;0;0;0mwhat \u001b[0m\u001b[38;2;177;255;177m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;255;244;244m\u001b[48;2;0;0;0mleft \u001b[0m\n",
      "\u001b[38;2;208;255;208m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;227;255;227m\u001b[48;2;0;0;0mhuman \u001b[0m\u001b[38;2;244;255;244m\u001b[48;2;0;0;0mrace \u001b[0m\u001b[38;2;255;233;233m\u001b[48;2;0;0;0mthat \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;236;255;236m\u001b[48;2;0;0;0mfine \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0mpremise \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mfor \u001b[0m\u001b[38;2;255;168;168m\u001b[48;2;0;0;0man \u001b[0m\u001b[38;2;234;255;234m\u001b[48;2;0;0;0maction \u001b[0m\u001b[38;2;227;255;227m\u001b[48;2;0;0;0mpacked \u001b[0m\u001b[38;2;90;255;90m\u001b[48;2;0;0;0msci \u001b[0m\u001b[38;2;102;255;102m\u001b[48;2;0;0;0mfi \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0manimated \u001b[0m\u001b[38;2;255;204;204m\u001b[48;2;0;0;0mmovie \u001b[0m\u001b[38;2;255;228;228m\u001b[48;2;0;0;0mbut \u001b[0m\u001b[38;2;255;150;150m\u001b[48;2;0;0;0mthere \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;175;175m\u001b[48;2;0;0;0mno \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mpayoff \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;239;255;239m\u001b[48;2;0;0;0mstory \u001b[0m\u001b[38;2;250;255;250m\u001b[48;2;0;0;0mtakes \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\n",
      "\u001b[38;2;255;232;232m\u001b[48;2;0;0;0mmain \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mcharacters \u001b[0m\u001b[38;2;255;224;224m\u001b[48;2;0;0;0mall \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0mover \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;188;255;188m\u001b[48;2;0;0;0mgalaxy \u001b[0m\u001b[38;2;255;128;128m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mtheir \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0msearch \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mfor \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;244;255;244m\u001b[48;2;0;0;0mlegendary \u001b[0m\u001b[38;2;234;255;234m\u001b[48;2;0;0;0mship \u001b[0m\u001b[38;2;255;233;233m\u001b[48;2;0;0;0mthat \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;215;255;215m\u001b[48;2;0;0;0mevil \u001b[0m\u001b[38;2;255;251;251m\u001b[48;2;0;0;0mdredge \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0maliens \u001b[0m\u001b[38;2;237;255;237m\u001b[48;2;0;0;0mwant \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;224;255;224m\u001b[48;2;0;0;0mdestroy \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mfor \u001b[0m\u001b[38;2;255;175;175m\u001b[48;2;0;0;0mno \u001b[0m\n",
      "\u001b[38;2;255;220;220m\u001b[48;2;0;0;0mapparent \u001b[0m\u001b[38;2;255;217;217m\u001b[48;2;0;0;0mreason \u001b[0m\u001b[38;2;255;180;180m\u001b[48;2;0;0;0mso \u001b[0m\u001b[38;2;255;128;128m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mprocess \u001b[0m\u001b[38;2;255;233;233m\u001b[48;2;0;0;0mwe \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0mget \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;255;241;241m\u001b[48;2;0;0;0mlot \u001b[0m\u001b[38;2;208;255;208m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0mspaceship \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mfights \u001b[0m\u001b[38;2;250;255;250m\u001b[48;2;0;0;0mfistfights \u001b[0m\u001b[38;2;255;242;242m\u001b[48;2;0;0;0mblaster \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mfights \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mmore \u001b[0m\u001b[38;2;255;225;225m\u001b[48;2;0;0;0mdouble \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0mcrosses \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mthan \u001b[0m\u001b[38;2;244;255;244m\u001b[48;2;0;0;0myou \u001b[0m\u001b[38;2;255;227;227m\u001b[48;2;0;0;0mcan \u001b[0m\n",
      "\u001b[38;2;255;239;239m\u001b[48;2;0;0;0mshake \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;255;248;248m\u001b[48;2;0;0;0mstick \u001b[0m\u001b[38;2;255;213;213m\u001b[48;2;0;0;0mat \u001b[0m\u001b[38;2;255;150;150m\u001b[48;2;0;0;0mthere \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;180;180m\u001b[48;2;0;0;0mso \u001b[0m\u001b[38;2;255;210;210m\u001b[48;2;0;0;0mmuch \u001b[0m\u001b[38;2;255;229;229m\u001b[48;2;0;0;0mpointless \u001b[0m\u001b[38;2;90;255;90m\u001b[48;2;0;0;0msci \u001b[0m\u001b[38;2;102;255;102m\u001b[48;2;0;0;0mfi \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mbanterit \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;219;219m\u001b[48;2;0;0;0mtoo \u001b[0m\u001b[38;2;255;210;210m\u001b[48;2;0;0;0mmuch \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;239;255;239m\u001b[48;2;0;0;0mtake \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;188;255;188m\u001b[48;2;0;0;0mgalaxy \u001b[0m\u001b[38;2;255;227;227m\u001b[48;2;0;0;0mhere \u001b[0m\u001b[38;2;177;255;177m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mtotal \u001b[0m\u001b[38;2;255;219;219m\u001b[48;2;0;0;0mrip \u001b[0m\u001b[38;2;255;192;192m\u001b[48;2;0;0;0moff \u001b[0m\u001b[38;2;208;255;208m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;222;255;222m\u001b[48;2;0;0;0mstar \u001b[0m\u001b[38;2;200;255;200m\u001b[48;2;0;0;0mwars \u001b[0m\n",
      "\u001b[38;2;255;245;245m\u001b[48;2;0;0;0muniverse \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mcreators \u001b[0m\u001b[38;2;255;108;108m\u001b[48;2;0;0;0mdo \u001b[0m\u001b[38;2;255;245;245m\u001b[48;2;0;0;0mn \u001b[0m\u001b[38;2;255;249;249m\u001b[48;2;0;0;0mt \u001b[0m\u001b[38;2;255;237;237m\u001b[48;2;0;0;0mbother \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0mfilling \u001b[0m\u001b[38;2;255;128;128m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;252;252m\u001b[48;2;0;0;0mbasic \u001b[0m\u001b[38;2;245;255;245m\u001b[48;2;0;0;0mdetails \u001b[0m\u001b[38;2;255;227;227m\u001b[48;2;0;0;0mwhich \u001b[0m\u001b[38;2;230;255;230m\u001b[48;2;0;0;0mmakes \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;239;255;239m\u001b[48;2;0;0;0mstory \u001b[0m\u001b[38;2;255;243;243m\u001b[48;2;0;0;0mconfusing \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mcharacters \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0munmotivated \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\n",
      "\u001b[38;2;253;255;253m\u001b[48;2;0;0;0msuperficial \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;188;188m\u001b[48;2;0;0;0mplot \u001b[0m\u001b[38;2;255;210;210m\u001b[48;2;0;0;0mjust \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0mplain \u001b[0m\u001b[38;2;255;208;208m\u001b[48;2;0;0;0mboring \u001b[0m\u001b[38;2;230;255;230m\u001b[48;2;0;0;0mdespite \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;244;244m\u001b[48;2;0;0;0mfantastic \u001b[0m\u001b[38;2;226;255;226m\u001b[48;2;0;0;0manimation \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;239;255;239m\u001b[48;2;0;0;0mspecial \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0meffects \u001b[0m\u001b[38;2;255;191;191m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;210;210m\u001b[48;2;0;0;0mjust \u001b[0m\u001b[38;2;255;231;231m\u001b[48;2;0;0;0mnot \u001b[0m\u001b[38;2;255;168;168m\u001b[48;2;0;0;0man \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0minteresting \u001b[0m\u001b[38;2;255;204;204m\u001b[48;2;0;0;0mmovie \u001b[0m"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________ imbalanced _________________\n",
      "\u001b[38;2;255;176;176m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mgood \u001b[0m\u001b[38;2;255;232;232m\u001b[48;2;0;0;0mthing \u001b[0m\u001b[38;2;237;255;237m\u001b[48;2;0;0;0mmost \u001b[0m\u001b[38;2;255;148;148m\u001b[48;2;0;0;0manimated \u001b[0m\u001b[38;2;178;255;178m\u001b[48;2;0;0;0msci \u001b[0m\u001b[38;2;189;255;189m\u001b[48;2;0;0;0mfi \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mmovies \u001b[0m\u001b[38;2;255;251;251m\u001b[48;2;0;0;0mcome \u001b[0m\u001b[38;2;235;255;235m\u001b[48;2;0;0;0mfrom \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mjapan \u001b[0m\u001b[38;2;255;168;168m\u001b[48;2;0;0;0mbecause \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mtitan \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0me \u001b[0m\u001b[38;2;161;255;161m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;240;255;240m\u001b[48;2;0;0;0mproof \u001b[0m\u001b[38;2;255;164;164m\u001b[48;2;0;0;0mthat \u001b[0m\u001b[38;2;255;221;221m\u001b[48;2;0;0;0mhollywood \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mdoes \u001b[0m\u001b[38;2;255;240;240m\u001b[48;2;0;0;0mn \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mt \u001b[0m\u001b[38;2;255;172;172m\u001b[48;2;0;0;0mhave \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;221;255;221m\u001b[48;2;0;0;0mclue \u001b[0m\n",
      "\u001b[38;2;251;255;251m\u001b[48;2;0;0;0mhow \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;49;49m\u001b[48;2;0;0;0mdo \u001b[0m\u001b[38;2;255;176;176m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0mi \u001b[0m\u001b[38;2;255;49;49m\u001b[48;2;0;0;0mdo \u001b[0m\u001b[38;2;255;240;240m\u001b[48;2;0;0;0mn \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mt \u001b[0m\u001b[38;2;255;214;214m\u001b[48;2;0;0;0mknow \u001b[0m\u001b[38;2;255;225;225m\u001b[48;2;0;0;0mwhat \u001b[0m\u001b[38;2;255;190;190m\u001b[48;2;0;0;0mthis \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mfilm \u001b[0m\u001b[38;2;161;255;161m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;255;96;96m\u001b[48;2;0;0;0msupposed \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;191;191m\u001b[48;2;0;0;0mbe \u001b[0m\u001b[38;2;255;206;206m\u001b[48;2;0;0;0mabout \u001b[0m\u001b[38;2;235;255;235m\u001b[48;2;0;0;0mfrom \u001b[0m\u001b[38;2;255;225;225m\u001b[48;2;0;0;0mwhat \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0mi \u001b[0m\u001b[38;2;244;255;244m\u001b[48;2;0;0;0mcan \u001b[0m\u001b[38;2;255;232;232m\u001b[48;2;0;0;0mtell \u001b[0m\u001b[38;2;255;176;176m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;206;206m\u001b[48;2;0;0;0mabout \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;234;255;234m\u001b[48;2;0;0;0myoung \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mman \u001b[0m\u001b[38;2;255;230;230m\u001b[48;2;0;0;0mnamed \u001b[0m\u001b[38;2;250;255;250m\u001b[48;2;0;0;0mkale \u001b[0m\u001b[38;2;227;255;227m\u001b[48;2;0;0;0mwho \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0mone \u001b[0m\u001b[38;2;174;255;174m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\n",
      "\u001b[38;2;255;163;163m\u001b[48;2;0;0;0mlast \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0msurvivors \u001b[0m\u001b[38;2;174;255;174m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;255;203;203m\u001b[48;2;0;0;0mearth \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;154;154m\u001b[48;2;0;0;0mearly \u001b[0m\u001b[38;2;255;204;204m\u001b[48;2;0;0;0m31st \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0mcentury \u001b[0m\u001b[38;2;227;255;227m\u001b[48;2;0;0;0mwho \u001b[0m\u001b[38;2;238;255;238m\u001b[48;2;0;0;0munknowingly \u001b[0m\u001b[38;2;255;246;246m\u001b[48;2;0;0;0mpossesses \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;250;255;250m\u001b[48;2;0;0;0mkey \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;187;187m\u001b[48;2;0;0;0msaving \u001b[0m\u001b[38;2;4;255;4m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mre \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mgenerating \u001b[0m\u001b[38;2;255;225;225m\u001b[48;2;0;0;0mwhat \u001b[0m\u001b[38;2;161;255;161m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;255;224;224m\u001b[48;2;0;0;0mleft \u001b[0m\n",
      "\u001b[38;2;174;255;174m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0mhuman \u001b[0m\u001b[38;2;239;255;239m\u001b[48;2;0;0;0mrace \u001b[0m\u001b[38;2;255;164;164m\u001b[48;2;0;0;0mthat \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;228;255;228m\u001b[48;2;0;0;0mfine \u001b[0m\u001b[38;2;255;247;247m\u001b[48;2;0;0;0mpremise \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mfor \u001b[0m\u001b[38;2;255;230;230m\u001b[48;2;0;0;0man \u001b[0m\u001b[38;2;255;213;213m\u001b[48;2;0;0;0maction \u001b[0m\u001b[38;2;243;255;243m\u001b[48;2;0;0;0mpacked \u001b[0m\u001b[38;2;178;255;178m\u001b[48;2;0;0;0msci \u001b[0m\u001b[38;2;189;255;189m\u001b[48;2;0;0;0mfi \u001b[0m\u001b[38;2;255;148;148m\u001b[48;2;0;0;0manimated \u001b[0m\u001b[38;2;255;202;202m\u001b[48;2;0;0;0mmovie \u001b[0m\u001b[38;2;244;255;244m\u001b[48;2;0;0;0mbut \u001b[0m\u001b[38;2;255;204;204m\u001b[48;2;0;0;0mthere \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;132;132m\u001b[48;2;0;0;0mno \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mpayoff \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mstory \u001b[0m\u001b[38;2;238;255;238m\u001b[48;2;0;0;0mtakes \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\n",
      "\u001b[38;2;255;221;221m\u001b[48;2;0;0;0mmain \u001b[0m\u001b[38;2;255;216;216m\u001b[48;2;0;0;0mcharacters \u001b[0m\u001b[38;2;255;226;226m\u001b[48;2;0;0;0mall \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mover \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0mgalaxy \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0mtheir \u001b[0m\u001b[38;2;255;244;244m\u001b[48;2;0;0;0msearch \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mfor \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;231;255;231m\u001b[48;2;0;0;0mlegendary \u001b[0m\u001b[38;2;213;255;213m\u001b[48;2;0;0;0mship \u001b[0m\u001b[38;2;255;164;164m\u001b[48;2;0;0;0mthat \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;211;255;211m\u001b[48;2;0;0;0mevil \u001b[0m\u001b[38;2;247;255;247m\u001b[48;2;0;0;0mdredge \u001b[0m\u001b[38;2;255;234;234m\u001b[48;2;0;0;0maliens \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0mwant \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;244;255;244m\u001b[48;2;0;0;0mdestroy \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mfor \u001b[0m\u001b[38;2;255;132;132m\u001b[48;2;0;0;0mno \u001b[0m\n",
      "\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mapparent \u001b[0m\u001b[38;2;255;167;167m\u001b[48;2;0;0;0mreason \u001b[0m\u001b[38;2;255;182;182m\u001b[48;2;0;0;0mso \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;244;255;244m\u001b[48;2;0;0;0mprocess \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mwe \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mget \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0mlot \u001b[0m\u001b[38;2;174;255;174m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mspaceship \u001b[0m\u001b[38;2;255;197;197m\u001b[48;2;0;0;0mfights \u001b[0m\u001b[38;2;252;255;252m\u001b[48;2;0;0;0mfistfights \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mblaster \u001b[0m\u001b[38;2;255;197;197m\u001b[48;2;0;0;0mfights \u001b[0m\u001b[38;2;4;255;4m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;233;255;233m\u001b[48;2;0;0;0mmore \u001b[0m\u001b[38;2;255;217;217m\u001b[48;2;0;0;0mdouble \u001b[0m\u001b[38;2;243;255;243m\u001b[48;2;0;0;0mcrosses \u001b[0m\u001b[38;2;249;255;249m\u001b[48;2;0;0;0mthan \u001b[0m\u001b[38;2;226;255;226m\u001b[48;2;0;0;0myou \u001b[0m\u001b[38;2;244;255;244m\u001b[48;2;0;0;0mcan \u001b[0m\n",
      "\u001b[38;2;255;230;230m\u001b[48;2;0;0;0mshake \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;255;177;177m\u001b[48;2;0;0;0mstick \u001b[0m\u001b[38;2;255;228;228m\u001b[48;2;0;0;0mat \u001b[0m\u001b[38;2;255;204;204m\u001b[48;2;0;0;0mthere \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;182;182m\u001b[48;2;0;0;0mso \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mmuch \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0mpointless \u001b[0m\u001b[38;2;178;255;178m\u001b[48;2;0;0;0msci \u001b[0m\u001b[38;2;189;255;189m\u001b[48;2;0;0;0mfi \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0mbanterit \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;192;192m\u001b[48;2;0;0;0mtoo \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mmuch \u001b[0m\u001b[38;2;255;0;0m\u001b[48;2;0;0;0mto \u001b[0m\u001b[38;2;255;232;232m\u001b[48;2;0;0;0mtake \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0mgalaxy \u001b[0m\u001b[38;2;251;255;251m\u001b[48;2;0;0;0mhere \u001b[0m\u001b[38;2;161;255;161m\u001b[48;2;0;0;0mis \u001b[0m\u001b[38;2;248;255;248m\u001b[48;2;0;0;0ma \u001b[0m\u001b[38;2;255;220;220m\u001b[48;2;0;0;0mtotal \u001b[0m\u001b[38;2;255;209;209m\u001b[48;2;0;0;0mrip \u001b[0m\u001b[38;2;255;155;155m\u001b[48;2;0;0;0moff \u001b[0m\u001b[38;2;174;255;174m\u001b[48;2;0;0;0mof \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;237;255;237m\u001b[48;2;0;0;0mstar \u001b[0m\u001b[38;2;214;255;214m\u001b[48;2;0;0;0mwars \u001b[0m\n",
      "\u001b[38;2;255;227;227m\u001b[48;2;0;0;0muniverse \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;220;220m\u001b[48;2;0;0;0mcreators \u001b[0m\u001b[38;2;255;49;49m\u001b[48;2;0;0;0mdo \u001b[0m\u001b[38;2;255;240;240m\u001b[48;2;0;0;0mn \u001b[0m\u001b[38;2;253;255;253m\u001b[48;2;0;0;0mt \u001b[0m\u001b[38;2;255;187;187m\u001b[48;2;0;0;0mbother \u001b[0m\u001b[38;2;255;242;242m\u001b[48;2;0;0;0mfilling \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0min \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;250;250m\u001b[48;2;0;0;0mbasic \u001b[0m\u001b[38;2;235;255;235m\u001b[48;2;0;0;0mdetails \u001b[0m\u001b[38;2;255;236;236m\u001b[48;2;0;0;0mwhich \u001b[0m\u001b[38;2;201;255;201m\u001b[48;2;0;0;0mmakes \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;235;235m\u001b[48;2;0;0;0mstory \u001b[0m\u001b[38;2;246;255;246m\u001b[48;2;0;0;0mconfusing \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;216;216m\u001b[48;2;0;0;0mcharacters \u001b[0m\u001b[38;2;241;255;241m\u001b[48;2;0;0;0munmotivated \u001b[0m\u001b[38;2;4;255;4m\u001b[48;2;0;0;0mand \u001b[0m\n",
      "\u001b[38;2;255;194;194m\u001b[48;2;0;0;0msuperficial \u001b[0m\u001b[38;2;4;255;4m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;255;189;189m\u001b[48;2;0;0;0mplot \u001b[0m\u001b[38;2;255;157;157m\u001b[48;2;0;0;0mjust \u001b[0m\u001b[38;2;255;160;160m\u001b[48;2;0;0;0mplain \u001b[0m\u001b[38;2;255;194;194m\u001b[48;2;0;0;0mboring \u001b[0m\u001b[38;2;214;255;214m\u001b[48;2;0;0;0mdespite \u001b[0m\u001b[38;2;0;255;0m\u001b[48;2;0;0;0mthe \u001b[0m\u001b[38;2;242;255;242m\u001b[48;2;0;0;0mfantastic \u001b[0m\u001b[38;2;242;255;242m\u001b[48;2;0;0;0manimation \u001b[0m\u001b[38;2;4;255;4m\u001b[48;2;0;0;0mand \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0mspecial \u001b[0m\u001b[38;2;254;255;254m\u001b[48;2;0;0;0meffects \u001b[0m\u001b[38;2;255;176;176m\u001b[48;2;0;0;0mit \u001b[0m\u001b[38;2;255;253;253m\u001b[48;2;0;0;0ms \u001b[0m\u001b[38;2;255;157;157m\u001b[48;2;0;0;0mjust \u001b[0m\u001b[38;2;255;245;245m\u001b[48;2;0;0;0mnot \u001b[0m\u001b[38;2;255;230;230m\u001b[48;2;0;0;0man \u001b[0m\u001b[38;2;255;238;238m\u001b[48;2;0;0;0minteresting \u001b[0m\u001b[38;2;255;202;202m\u001b[48;2;0;0;0mmovie \u001b[0m"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "plt.rc('font', size=SMALL_SIZE)  \n",
    "def color_output(words, explanations):\n",
    "    coloring_range = ( np.min(explanations), np.max(explanations))\n",
    "    l=0\n",
    "    for j in range(len(words)):\n",
    "        if explanations[j]<0:\n",
    "            perc = explanations[j]/coloring_range[0]\n",
    "            r, g, b = 255,int(-255*perc+255),int(-255*perc+255)\n",
    "        else:\n",
    "            perc = explanations[j]/coloring_range[1]\n",
    "            r, g, b = int(-255*perc+255),255,int(-255*perc+255)\n",
    "        l+=len(words[j])\n",
    "        if l>100:\n",
    "            print(\"\\n\",end=\"\")\n",
    "            l=0\n",
    "        print(f'\\033[38;2;{r};{g};{b}m\\033[48;2;0;0;0m{words[j]} \\033[0m', end=\"\") \n",
    "    \n",
    "    n = 50\n",
    "    lin_1 = np.linspace(coloring_range[0],0,n)\n",
    "    diff_1 = lin_1[1]-lin_1[0]\n",
    "    lin_2 = np.linspace(0, coloring_range[1],n)\n",
    "    diff_2 = lin_2[1]-lin_2[0]\n",
    "    plt.style.use('dark_background')\n",
    "    fig, ax = plt.subplots(figsize=(5,1/2))\n",
    "    plt.plot()\n",
    "\n",
    "    for i in range(n):\n",
    "        perc = (lin_1[0]-lin_1[i])/coloring_range[0]\n",
    "        rect = patches.Rectangle((coloring_range[0]-lin_1[i], 0), diff_1, 1, facecolor=(1,int(-255*perc+255)/255,int(-255*perc+255)/255))\n",
    "        ax.add_patch(rect)\n",
    "        perc = (lin_2[i])/coloring_range[1]\n",
    "        rect = patches.Rectangle((lin_2[i], 0), diff_2, 1, facecolor=(int(-255*perc+255)/255,1,int(-255*perc+255)/255))\n",
    "        ax.add_patch(rect)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    plt.title(\"LIME value\")\n",
    "    plt.show()\n",
    "    \n",
    "df_tmp = df[(df[\"id\"]==4)&((df[\"Imbalance %\"].astype(int)==20)| (df[\"Imbalance %\"].astype(int)==100))&(df[\"Model ID\"].astype(int)==0)&(df[\"Balancing method\"]!=\"LLama\")]\n",
    "for val in df_tmp.values:\n",
    "    print(f\"_________________ {val[0]} _________________\")      \n",
    "    color_output(ast.literal_eval(val[5]), ast.literal_eval(val[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model ID</th>\n",
       "      <th>Imbalance %</th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>spearman_original</th>\n",
       "      <th>normality_original</th>\n",
       "      <th>imbalanced</th>\n",
       "      <th>spearman_imbalanced</th>\n",
       "      <th>normality_imbalanced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>LLama</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.502280</td>\n",
       "      <td>2.663103e-104</td>\n",
       "      <td>2.043570e-07</td>\n",
       "      <td>0.598325</td>\n",
       "      <td>2.663103e-104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>LLama</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.595077</td>\n",
       "      <td>2.554212e-68</td>\n",
       "      <td>1.076253e-10</td>\n",
       "      <td>0.350683</td>\n",
       "      <td>2.554212e-68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.516538</td>\n",
       "      <td>1.581972e-105</td>\n",
       "      <td>8.233361e-07</td>\n",
       "      <td>0.590893</td>\n",
       "      <td>1.581972e-105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>0.539125</td>\n",
       "      <td>2.120496e-68</td>\n",
       "      <td>2.962350e-11</td>\n",
       "      <td>0.246128</td>\n",
       "      <td>2.120496e-68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>LLama</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.606441</td>\n",
       "      <td>1.060680e-103</td>\n",
       "      <td>1.818237e-03</td>\n",
       "      <td>0.478171</td>\n",
       "      <td>1.060680e-103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model ID Imbalance % Balancing method  id  original  spearman_original  normality_original    imbalanced  spearman_imbalanced  normality_imbalanced\n",
       "0        0          10            LLama   0  0.000045           0.502280       2.663103e-104  2.043570e-07             0.598325         2.663103e-104\n",
       "1        0          10            LLama   1  0.003033           0.595077        2.554212e-68  1.076253e-10             0.350683          2.554212e-68\n",
       "2        0          10    LLama_complex   0  0.000065           0.516538       1.581972e-105  8.233361e-07             0.590893         1.581972e-105\n",
       "3        0          10    LLama_complex   1  0.007808           0.539125        2.120496e-68  2.962350e-11             0.246128          2.120496e-68\n",
       "4        1          10            LLama   0  0.000767           0.606441       1.060680e-103  1.818237e-03             0.478171         1.060680e-103"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method used to calculate p_values from wilcoxon-signed rank test between two explanations\n",
    "def get_p_values(df, lime=\"lime_sentence\"):\n",
    "    results = []\n",
    "    \n",
    "    # Selecting model trained on original data for comparison\n",
    "    original = df[df[\"Balancing method\"]==\"original\"]\n",
    "\n",
    "    # Looping through imbalance % model id balancing method and instances\n",
    "    for imbalance in np.unique(df[\"Imbalance %\"]):\n",
    "        for model_id in np.unique(df[\"Model ID\"]):\n",
    "            # Selecting model trained on imbalanced data for comparison\n",
    "            df_tmp = df[(df[\"Imbalance %\"]==imbalance)&(df[\"Model ID\"]==model_id)&(df[\"Balancing method\"]!=\"original\")]\n",
    "            imbalanced = df_tmp[df_tmp[\"Balancing method\"]==\"imbalanced\"]\n",
    "            # Filtering models based on balanced datasets\n",
    "            other_methods = df_tmp[df_tmp[\"Balancing method\"]!=\"imbalanced\"]\n",
    "            for method in np.unique(other_methods[\"Balancing method\"]):\n",
    "                for i in np.unique(other_methods.id)[:2]:\n",
    "                    # Saving basic model identification\n",
    "                    res = {}\n",
    "                    res[\"Model ID\"] = model_id\n",
    "                    res[\"Imbalance %\"] = imbalance\n",
    "                    res[\"Balancing method\"] = method\n",
    "                    res[\"id\"] = i\n",
    "                    # Comparing xai from original model and xai from balanced model\n",
    "                    df_tmp = other_methods[other_methods[\"Balancing method\"]==method]\n",
    "                    x1 = ast.literal_eval(df_tmp[df_tmp.id==i][lime].values[0])\n",
    "                    x2 = ast.literal_eval(original[original.id==i][lime].values[0])\n",
    "                    res[\"original\"] = stats.wilcoxon(x1, x2)[1]\n",
    "                    res[\"spearman_original\"] = spearmanr(x1, x2)[0]\n",
    "                    res[\"normality_original\"] = kstest(np.array(x1)-np.array(x2), 'norm')[1]\n",
    "                    # Comparing xai from imbalanced model and xai from balanced model if imbalanced model was not bad (acc>0.6 & f1!=0)\n",
    "                    if len(imbalanced)>0:\n",
    "                        x3 = ast.literal_eval(imbalanced[imbalanced.id==i][lime].values[0])\n",
    "                        res[\"imbalanced\"] = stats.wilcoxon(x1, x3)[1]\n",
    "                        res[\"spearman_imbalanced\"] = spearmanr(x1, x3)[0]\n",
    "                        res[\"normality_imbalanced\"] = kstest(np.array(x1)-np.array(x2), 'norm')[1]\n",
    "                    results.append(res)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "results_sentence = get_p_values(df, lime=\"lime_sentence\")\n",
    "results_word = get_p_values(df, lime=\"lime_word\")\n",
    "results_sentence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model ID</th>\n",
       "      <th>Imbalance %</th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>spearman_original</th>\n",
       "      <th>normality_original</th>\n",
       "      <th>imbalanced</th>\n",
       "      <th>spearman_imbalanced</th>\n",
       "      <th>normality_imbalanced</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model name</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mcc</th>\n",
       "      <th>auc</th>\n",
       "      <th>spearman</th>\n",
       "      <th>spearman_pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>LLama</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.746986</td>\n",
       "      <td>9.353290e-108</td>\n",
       "      <td>4.191504e-05</td>\n",
       "      <td>0.727136</td>\n",
       "      <td>9.353290e-108</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.390645</td>\n",
       "      <td>0.8731</td>\n",
       "      <td>0.984807</td>\n",
       "      <td>2.288834e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>LLama</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.698369</td>\n",
       "      <td>3.983273e-71</td>\n",
       "      <td>2.213374e-07</td>\n",
       "      <td>0.682148</td>\n",
       "      <td>3.983273e-71</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.390645</td>\n",
       "      <td>0.8731</td>\n",
       "      <td>0.984807</td>\n",
       "      <td>2.288834e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.735113</td>\n",
       "      <td>1.494479e-109</td>\n",
       "      <td>1.547129e-04</td>\n",
       "      <td>0.707549</td>\n",
       "      <td>1.494479e-109</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.390645</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>0.972649</td>\n",
       "      <td>2.368935e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.685160</td>\n",
       "      <td>8.378749e-71</td>\n",
       "      <td>4.122172e-09</td>\n",
       "      <td>0.662574</td>\n",
       "      <td>8.378749e-71</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.390645</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>0.972649</td>\n",
       "      <td>2.368935e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>LLama</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.671294</td>\n",
       "      <td>9.252907e-108</td>\n",
       "      <td>5.499830e-07</td>\n",
       "      <td>0.692050</td>\n",
       "      <td>9.252907e-108</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.482805</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0.954412</td>\n",
       "      <td>1.788267e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model ID Imbalance % Balancing method  id  original  spearman_original  normality_original    imbalanced  spearman_imbalanced  normality_imbalanced  ...  Unnamed: 0  Model name    acc        f1  precision  recall       mcc     auc  spearman  spearman_pval\n",
       "20        0          20            LLama   0  0.000741           0.746986       9.353290e-108  4.191504e-05             0.727136         9.353290e-108  ...          49         SVM  0.645  0.466165   0.939394    0.31  0.390645  0.8731  0.984807   2.288834e-07\n",
       "21        0          20            LLama   1  0.001759           0.698369        3.983273e-71  2.213374e-07             0.682148          3.983273e-71  ...          49         SVM  0.645  0.466165   0.939394    0.31  0.390645  0.8731  0.984807   2.288834e-07\n",
       "22        0          20    LLama_complex   0  0.000717           0.735113       1.494479e-109  1.547129e-04             0.707549         1.494479e-109  ...          59         SVM  0.645  0.466165   0.939394    0.31  0.390645  0.8817  0.972649   2.368935e-06\n",
       "23        0          20    LLama_complex   1  0.001954           0.685160        8.378749e-71  4.122172e-09             0.662574          8.378749e-71  ...          59         SVM  0.645  0.466165   0.939394    0.31  0.390645  0.8817  0.972649   2.368935e-06\n",
       "24        1          20            LLama   0  0.000019           0.671294       9.252907e-108  5.499830e-07             0.692050         9.252907e-108  ...          46         SVM  0.700  0.583333   0.954545    0.42  0.482805  0.8508  0.954412   1.788267e-05\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(110, 21)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method used to join results and metrics tables\n",
    "def add_metrics(results, metrics):\n",
    "    \n",
    "    # Changing column types to get agreement between tables\n",
    "    results['Model ID'] = results['Model ID'].astype(str)\n",
    "    metrics['Model ID'] = metrics['Model ID'].astype(str)\n",
    "    results['Imbalance %'] = results['Imbalance %'].astype(str)\n",
    "    metrics['Imbalance %'] = metrics['Imbalance %'].astype(str)\n",
    "    \n",
    "    # Merging tables\n",
    "    final = results.merge(metrics, on=['Model ID', 'Imbalance %', 'Balancing method'], how='left')\n",
    "    \n",
    "    # Removal of bad models that slipped through initial filtering due to a spelling mistake\n",
    "    return final[(final[\"acc\"]>=0.6) & (final[\"f1\"]!=0)]\n",
    "\n",
    "\n",
    "# Adding metric values \n",
    "metrics = pd.read_csv(\"nlpaug_SVM.csv\")\n",
    "final_sentence = add_metrics(results_sentence, metrics)\n",
    "final_word = add_metrics(results_word, metrics)\n",
    "display(final_sentence.head())\n",
    "final_sentence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are differences between lime normally distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normality_original</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normality_imbalanced</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean  median  rejection rate\n",
       "normality_original     0.0     0.0             1.0\n",
       "normality_imbalanced   0.0     0.0             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normality_original</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normality_imbalanced</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean  median  rejection rate\n",
       "normality_original     0.0     0.0             1.0\n",
       "normality_imbalanced   0.0     0.0             1.0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sentence\")\n",
    "df_tmp = final_sentence[[\"normality_original\", \"normality_imbalanced\", \"f1\"]].dropna()\n",
    "\n",
    "df_tmp = df_tmp.drop(\"f1\", axis=1)\n",
    "# Calculating descriptive statistics\n",
    "display(pd.DataFrame(data={\"mean\": np.round(np.mean(df_tmp, axis=0), 4),\n",
    "                    \"median\": np.round(np.median(df_tmp, axis=0), 4),\n",
    "                    \"rejection rate\": np.round(np.mean(df_tmp<0.05, axis=0), 4) }))\n",
    "\n",
    "print(\"Word\")\n",
    "df_tmp = final_sentence[[\"normality_original\", \"normality_imbalanced\", \"f1\"]].dropna()\n",
    "\n",
    "df_tmp = df_tmp.drop(\"f1\", axis=1)\n",
    "# Calculating descriptive statistics\n",
    "pd.DataFrame(data={\"mean\": np.round(np.mean(df_tmp, axis=0), 4),\n",
    "                    \"median\": np.round(np.median(df_tmp, axis=0), 4),\n",
    "                    \"rejection rate\": np.round(np.mean(df_tmp<0.05, axis=0), 4) })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are balanced models more similar to original or imbalanced model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.7364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalanced</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean  median  rejection rate\n",
       "original    0.1030  0.0008          0.7364\n",
       "imbalanced  0.0222  0.0000          0.9091"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method used to calculate descriptive statistics of p-values comparing XAI of balanced models to XAI of original and imbalanced models\n",
    "def similarity_balanced_imbalanced(final, threshold = None, spearman=False):\n",
    "    # Filtering models if threshold was provided\n",
    "    if 1-spearman:\n",
    "        df_tmp = final[[\"original\", \"imbalanced\", \"f1\"]].dropna()\n",
    "    else:\n",
    "        df_tmp = final[[\"spearman_original\", \"spearman_imbalanced\", \"f1\"]].dropna()\n",
    "    if threshold != None:\n",
    "        df_tmp = df_tmp[df_tmp.f1>=threshold]\n",
    "    df_tmp = df_tmp.drop(\"f1\", axis=1)\n",
    "    # Calculating descriptive statistics\n",
    "    res = pd.DataFrame(data={\"mean\": np.round(np.mean(df_tmp, axis=0), 4),\n",
    "                        \"median\": np.round(np.median(df_tmp, axis=0), 4),\n",
    "                        \"rejection rate\": np.round(np.mean(df_tmp<0.05, axis=0), 4) })\n",
    "    if spearman:\n",
    "        res=res.drop([\"rejection rate\"], axis=1)\n",
    "    return res\n",
    "\n",
    "similarity_balanced_imbalanced(final_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.4641</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>0.0455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalanced</th>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.1179</td>\n",
       "      <td>0.2636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean  median  rejection rate\n",
       "original    0.4641  0.4536          0.0455\n",
       "imbalanced  0.3072  0.1179          0.2636"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_balanced_imbalanced(final_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spearman_original</th>\n",
       "      <td>0.7411</td>\n",
       "      <td>0.7773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_imbalanced</th>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.7609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean  median\n",
       "spearman_original    0.7411  0.7773\n",
       "spearman_imbalanced  0.7173  0.7609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spearman_original</th>\n",
       "      <td>0.7419</td>\n",
       "      <td>0.7838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_imbalanced</th>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.7493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean  median\n",
       "spearman_original    0.7419  0.7838\n",
       "spearman_imbalanced  0.7388  0.7493"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sentence\")\n",
    "display(similarity_balanced_imbalanced(final_sentence, spearman = True))\n",
    "print(\"Word\")\n",
    "similarity_balanced_imbalanced(final_word, spearman = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which method results in models the most similar to original model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contextual_word_embedding</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROS</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spelling_mistake</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Translation</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing method    mean  median  rejection rate\n",
       "0  Contextual_word_embedding  0.1371  0.0466            0.50\n",
       "1                      LLama  0.0908  0.0001            0.85\n",
       "2              LLama_complex  0.0751  0.0002            0.90\n",
       "3                        ROS  0.2123  0.1444            0.30\n",
       "4           Spelling_mistake  0.2083  0.0556            0.50\n",
       "5              Summarization  0.0000  0.0000            1.00\n",
       "6        Synonym replacement  0.2432  0.1078            0.30\n",
       "7                Translation  0.0000  0.0000            1.00\n",
       "8                 paraphrase  0.0000  0.0000            1.00"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method used to calculate descriptive statistics of p-values comparing XAI of balanced models to XAI of original model with regard to all balancing methods\n",
    "def similarity_balancing_methods(final, threshold = None, spearman = False):\n",
    "    # Filtering models if threshold was provided\n",
    "    df_tmp = final[[\"Balancing method\", \"original\", \"f1\"]].dropna() if 1-spearman else final[[\"Balancing method\", \"spearman_original\", \"f1\"]].dropna()\n",
    "    if threshold != None:\n",
    "        df_tmp = df_tmp[df_tmp.f1>=threshold]\n",
    "    df_tmp = df_tmp.drop(\"f1\", axis=1)\n",
    "    res = []\n",
    "    # Calculating descriptive statistics\n",
    "    for method in np.unique(df_tmp[\"Balancing method\"]):\n",
    "        df_ = df_tmp[df_tmp[\"Balancing method\"]==method][\"original\"] if 1-spearman else df_tmp[df_tmp[\"Balancing method\"]==method][\"spearman_original\"]\n",
    "        res.append([method, np.round(np.mean(df_),4), np.round(np.median(df_),4), np.round(np.mean(df_<0.05),4)])\n",
    "    r = pd.DataFrame(res)\n",
    "    r.columns = [\"Balancing method\", \"mean\", \"median\", \"rejection rate\"]\n",
    "    if spearman:\n",
    "        r = r.drop(\"rejection rate\", axis=1)\n",
    "    return r\n",
    "\n",
    "\n",
    "similarity_balancing_methods(final_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contextual_word_embedding</td>\n",
       "      <td>0.5706</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.5277</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.5681</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROS</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.5421</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spelling_mistake</td>\n",
       "      <td>0.5583</td>\n",
       "      <td>0.5789</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>0.5549</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Translation</td>\n",
       "      <td>0.1153</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>0.5307</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing method    mean  median  rejection rate\n",
       "0  Contextual_word_embedding  0.5706  0.6581            0.00\n",
       "1                      LLama  0.4978  0.5277            0.05\n",
       "2              LLama_complex  0.5217  0.5681            0.00\n",
       "3                        ROS  0.5391  0.5421            0.00\n",
       "4           Spelling_mistake  0.5583  0.5789            0.00\n",
       "5              Summarization  0.1970  0.1365            0.10\n",
       "6        Synonym replacement  0.5549  0.5944            0.00\n",
       "7                Translation  0.1153  0.0946            0.30\n",
       "8                 paraphrase  0.5307  0.4390            0.00"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_balancing_methods(final_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contextual_word_embedding</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.8558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>0.8066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0.7701</td>\n",
       "      <td>0.8041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROS</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>0.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spelling_mistake</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.8638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.4701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.8737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Translation</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>0.6981</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing method    mean  median\n",
       "0  Contextual_word_embedding  0.8246  0.8558\n",
       "1                      LLama  0.7764  0.8066\n",
       "2              LLama_complex  0.7701  0.8041\n",
       "3                        ROS  0.8351  0.8552\n",
       "4           Spelling_mistake  0.8571  0.8638\n",
       "5              Summarization  0.4885  0.4701\n",
       "6        Synonym replacement  0.8537  0.8737\n",
       "7                Translation  0.5014  0.4882\n",
       "8                 paraphrase  0.6981  0.6900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contextual_word_embedding</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.8168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.7481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.7376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROS</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spelling_mistake</td>\n",
       "      <td>0.8010</td>\n",
       "      <td>0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.5846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>0.8181</td>\n",
       "      <td>0.8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Translation</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>0.7924</td>\n",
       "      <td>0.7931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing method    mean  median\n",
       "0  Contextual_word_embedding  0.8030  0.8168\n",
       "1                      LLama  0.7232  0.7481\n",
       "2              LLama_complex  0.7225  0.7376\n",
       "3                        ROS  0.8065  0.8261\n",
       "4           Spelling_mistake  0.8010  0.8059\n",
       "5              Summarization  0.6156  0.5846\n",
       "6        Synonym replacement  0.8181  0.8320\n",
       "7                Translation  0.6335  0.6325\n",
       "8                 paraphrase  0.7924  0.7931"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sentence\")\n",
    "display(similarity_balancing_methods(final_sentence, spearman = True))\n",
    "print(\"Word\")\n",
    "similarity_balancing_methods(final_word, spearman = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now what if we remove models that performed significantly worse than original model based on f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of original model: 0.84\n",
      "Threshold- 80% of F1 of original model: 0.67\n",
      "This further removes 53 (77.9%) of remaining models\n"
     ]
    }
   ],
   "source": [
    "# Getting f1 score of model trained on original data\n",
    "f1 = metrics[(metrics[\"Balancing method\"]==\"original\")&(metrics[\"Model name\"]==df[\"Model name\"].values[0])].f1.values[0]\n",
    "print(f\"F1 score of original model: {np.round(f1, 2)}\")\n",
    "print(f\"Threshold- 80% of F1 of original model: {np.round(f1*0.8, 2)}\")\n",
    "# Calculating threshold\n",
    "threshold = np.round(f1*0.8, 2)\n",
    "metrics_temp = metrics[(metrics.acc>0.6) & (metrics.f1!=0)]\n",
    "print(f\"This further removes {len(metrics_temp[metrics_temp.f1>threshold])} ({np.round(len(metrics_temp[metrics_temp.f1>threshold])/len(metrics_temp)*100,1)}%) of remaining models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are balanced models more similar to original or imbalanced model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.6778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalanced</th>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean  median  rejection rate\n",
       "original    0.1258  0.0067          0.6778\n",
       "imbalanced  0.0271  0.0002          0.8889"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_balanced_imbalanced(final_sentence, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.4567</td>\n",
       "      <td>0.4488</td>\n",
       "      <td>0.0444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalanced</th>\n",
       "      <td>0.3693</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean  median  rejection rate\n",
       "original    0.4567  0.4488          0.0444\n",
       "imbalanced  0.3693  0.1667          0.1222"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_balanced_imbalanced(final_word, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spearman_original</th>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.8469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_imbalanced</th>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.7835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean  median\n",
       "spearman_original    0.7619  0.8469\n",
       "spearman_imbalanced  0.7358  0.7835"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spearman_original</th>\n",
       "      <td>0.7757</td>\n",
       "      <td>0.8128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_imbalanced</th>\n",
       "      <td>0.7649</td>\n",
       "      <td>0.7691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean  median\n",
       "spearman_original    0.7757  0.8128\n",
       "spearman_imbalanced  0.7649  0.7691"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sentence\")\n",
    "display(similarity_balanced_imbalanced(final_sentence, threshold, spearman = True))\n",
    "print(\"Word\")\n",
    "similarity_balanced_imbalanced(final_word, threshold, spearman = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which method results in models the most similar to original model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contextual_word_embedding</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0.1498</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROS</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spelling_mistake</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Translation</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing method    mean  median  rejection rate\n",
       "0  Contextual_word_embedding  0.1371  0.0466             0.5\n",
       "1                      LLama  0.1813  0.0060             0.7\n",
       "2              LLama_complex  0.1498  0.0012             0.8\n",
       "3                        ROS  0.2123  0.1444             0.3\n",
       "4           Spelling_mistake  0.2083  0.0556             0.5\n",
       "5              Summarization  0.0000  0.0000             1.0\n",
       "6        Synonym replacement  0.2432  0.1078             0.3\n",
       "7                Translation  0.0000  0.0000             1.0\n",
       "8                 paraphrase  0.0000  0.0000             1.0"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_balancing_methods(final_sentence, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>rejection rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contextual_word_embedding</td>\n",
       "      <td>0.5706</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama</td>\n",
       "      <td>0.5158</td>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0.5284</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROS</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.5421</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spelling_mistake</td>\n",
       "      <td>0.5583</td>\n",
       "      <td>0.5789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>0.5549</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Translation</td>\n",
       "      <td>0.1153</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>0.5307</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing method    mean  median  rejection rate\n",
       "0  Contextual_word_embedding  0.5706  0.6581             0.0\n",
       "1                      LLama  0.5158  0.5414             0.0\n",
       "2              LLama_complex  0.5284  0.5816             0.0\n",
       "3                        ROS  0.5391  0.5421             0.0\n",
       "4           Spelling_mistake  0.5583  0.5789             0.0\n",
       "5              Summarization  0.1970  0.1365             0.1\n",
       "6        Synonym replacement  0.5549  0.5944             0.0\n",
       "7                Translation  0.1153  0.0946             0.3\n",
       "8                 paraphrase  0.5307  0.4390             0.0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_balancing_methods(final_word, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contextual_word_embedding</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.8558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.8984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.9018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROS</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>0.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spelling_mistake</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.8638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.4701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.8737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Translation</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>0.6981</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing method    mean  median\n",
       "0  Contextual_word_embedding  0.8246  0.8558\n",
       "1                      LLama  0.8988  0.8984\n",
       "2              LLama_complex  0.8997  0.9018\n",
       "3                        ROS  0.8351  0.8552\n",
       "4           Spelling_mistake  0.8571  0.8638\n",
       "5              Summarization  0.4885  0.4701\n",
       "6        Synonym replacement  0.8537  0.8737\n",
       "7                Translation  0.5014  0.4882\n",
       "8                 paraphrase  0.6981  0.6900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing method</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contextual_word_embedding</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.8168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLama_complex</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.8563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROS</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spelling_mistake</td>\n",
       "      <td>0.8010</td>\n",
       "      <td>0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.5846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synonym replacement</td>\n",
       "      <td>0.8181</td>\n",
       "      <td>0.8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Translation</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paraphrase</td>\n",
       "      <td>0.7924</td>\n",
       "      <td>0.7931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Balancing method    mean  median\n",
       "0  Contextual_word_embedding  0.8030  0.8168\n",
       "1                      LLama  0.8545  0.8560\n",
       "2              LLama_complex  0.8569  0.8563\n",
       "3                        ROS  0.8065  0.8261\n",
       "4           Spelling_mistake  0.8010  0.8059\n",
       "5              Summarization  0.6156  0.5846\n",
       "6        Synonym replacement  0.8181  0.8320\n",
       "7                Translation  0.6335  0.6325\n",
       "8                 paraphrase  0.7924  0.7931"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sentence\")\n",
    "display(similarity_balancing_methods(final_sentence, threshold, spearman = True))\n",
    "print(\"Word\")\n",
    "similarity_balancing_methods(final_word, threshold, spearman = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
