{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":10027310,"datasetId":6175078,"databundleVersionId":10298866},{"sourceType":"datasetVersion","sourceId":10445467,"datasetId":6423377,"databundleVersionId":10765663},{"sourceType":"datasetVersion","sourceId":10445502,"datasetId":6436467,"databundleVersionId":10765706},{"sourceType":"datasetVersion","sourceId":10406772,"datasetId":6448963,"databundleVersionId":10723270}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:59:31.693315Z","iopub.execute_input":"2025-01-11T22:59:31.693648Z","iopub.status.idle":"2025-01-11T22:59:37.084503Z","shell.execute_reply.started":"2025-01-11T22:59:31.693621Z","shell.execute_reply":"2025-01-11T22:59:37.083460Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.5)\nRequirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\nRequirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.24.0)\nRequirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.3)\nRequirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (10.4.0)\nRequirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.35.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.8.30)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.1)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.53.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport random\nimport pickle\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport lime\nfrom lime.lime_text import LimeTextExplainer\n\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom torch.utils.data import Dataset\nimport torch\n\nfrom sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n\nimport gc\nimport re\n\ndef set_seeds(seed=123):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\nset_seeds(seed=123)\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:59:37.086041Z","iopub.execute_input":"2025-01-11T22:59:37.086495Z","iopub.status.idle":"2025-01-11T22:59:50.905213Z","shell.execute_reply.started":"2025-01-11T22:59:37.086460Z","shell.execute_reply":"2025-01-11T22:59:50.904133Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# class used to store datasets in this project (required for object loading from pickle)\nclass TrainerDataset(Dataset):\n    def __init__(self, inputs, targets, tokenizer, evidences=None):\n        self.inputs = inputs\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.evidences=evidences\n\n        # Tokenize the input\n        self.tokenized_inputs = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")   \n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return InputFeatures(\n            input_ids=self.tokenized_inputs['input_ids'][idx],\n#             token_type_ids=self.tokenized_inputs['token_type_ids'][idx],\n            attention_mask=self.tokenized_inputs['attention_mask'][idx],\n            label=self.targets[idx])   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:59:50.907097Z","iopub.execute_input":"2025-01-11T22:59:50.907709Z","iopub.status.idle":"2025-01-11T22:59:50.915278Z","shell.execute_reply.started":"2025-01-11T22:59:50.907679Z","shell.execute_reply":"2025-01-11T22:59:50.914283Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Global variables\ntask = \"eraser_movie\"\nexplain_count = 40\nskip = 0\nmodels_dataset = \"models-test2\"\n\n\n# Loading the test dataset\nwith open(f\"/kaggle/input/balanced-datasets/{task}_test.obj\", 'rb') as pickle_file:\n    test_dataset = pickle.load(pickle_file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:59:50.916702Z","iopub.execute_input":"2025-01-11T22:59:50.917112Z","iopub.status.idle":"2025-01-11T22:59:52.140434Z","shell.execute_reply.started":"2025-01-11T22:59:50.917085Z","shell.execute_reply":"2025-01-11T22:59:52.139302Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Method used to get lime values of n instances from the test dataset staarting from the i-th instance using given model and tokenizer\ndef get_xai(i, n, model=None, tokenizer=None):\n\n    # Helper method used to get probas for all tested model types\n    def prob(data):\n        if str(type(model))==\"<class 'keras.src.models.sequential.Sequential'>\":\n            # Preprocess the data\n            max_len = model.input_shape[1] if hasattr(model, 'input_shape') else 512  \n            sequences = tokenizer.texts_to_sequences(data)\n            padded_sequences = pad_sequences(sequences, maxlen=max_len)\n            \n            # Return probas\n            probabilities = model.predict(padded_sequences, verbose=0)\n            return np.array([[1-x[0], x[0]] for x in probabilities])\n            \n          \n        elif str(type(model))==\"<class 'sklearn.svm._classes.SVC'>\":\n            # Preprocess the data\n            data = tokenizer.transform(data)\n            # Return probas\n            return np.array(model.predict_proba(data))\n\n        else:\n            # Tokenize all texts in the input list\n            inputs = tokenizer(data, padding=True, truncation=True, return_tensors=\"pt\")\n            \n            # Move inputs to the correct device\n            input_ids = inputs['input_ids'].to(device)\n            attention_mask = inputs['attention_mask'].to(device)\n            \n            # Get model predictions\n            with torch.no_grad():\n                pred = model(input_ids=input_ids.long(), \n                 attention_mask=attention_mask).logits\n            \n            # Convert logits to probabilities using softmax\n            probs = torch.nn.functional.softmax(pred, dim=-1).cpu().detach().numpy()\n            return probs\n            \n    \n\n    \n    attributions = []\n\n    # Load explainer object\n    explainer = LimeTextExplainer()\n    \n    for j in range(i, i+n):\n        # Getting initial parameters\n        set_seeds(seed=123)\n        input_text = test_dataset.inputs[j]\n        num_features = len(re.split(r'\\W+',test_dataset.inputs[i])) \n\n        # Calculating the explanations\n        explanation = explainer.explain_instance(\n            input_text,\n            lambda data: prob(data), \n            num_features=num_features if str(type(model))!=\"<class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'>\" else len(test_dataset.tokenized_inputs[j].tokens),\n            num_samples=400 if str(type(model))==\"<class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'>\" else 1000\n        )\n\n        # Saving the results\n        attributions.append(explanation)\n\n        # Memory clean up\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    return attributions\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:59:52.141687Z","iopub.execute_input":"2025-01-11T22:59:52.142014Z","iopub.status.idle":"2025-01-11T22:59:52.152044Z","shell.execute_reply.started":"2025-01-11T22:59:52.141988Z","shell.execute_reply":"2025-01-11T22:59:52.151202Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Looping through files in search of .csv file with model performance measures\nfor file in os.listdir(f\"/kaggle/input/{models_dataset}/\"):\n    if \".csv\"in file:\n        df = pd.read_csv(f\"/kaggle/input/{models_dataset}/\"+file)\n\n# Creatinng column with model names       \ndf[\"filename\"] = \"eraser_movie_\"+df[\"Imbalance %\"].astype(str)+\"_\"+df[\"Balancing method\"]+\"_\"+df[\"Model ID\"].astype(str)+\"_\"+df[\"Model name\"]+\".obj\"\ndf[\"filename\"] = df[\"filename\"].apply(lambda x: x if x in os.listdir(f\"/kaggle/input/{models_dataset}/\") else x.replace(\"eraser_movie\", \"erqaser_movie\"))\n\n# List of bad models\nbad_models = list(df[(df[\"f1\"]==0) | (df[\"acc\"]<0.6)][\"filename\"])\nprint(f\"This set of models contains {len(bad_models)} bad models, which are {np.round(100*len(bad_models)/len(df),2)}% of all models. XAI will not be calculated for them\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:09:06.663216Z","iopub.execute_input":"2025-01-12T01:09:06.663577Z","iopub.status.idle":"2025-01-12T01:09:06.767501Z","shell.execute_reply.started":"2025-01-12T01:09:06.663551Z","shell.execute_reply":"2025-01-12T01:09:06.766387Z"}},"outputs":[{"name":"stdout","text":"This set of models contains 127 bad models, which are 89.44% of all models. XAI will not be calculated for them\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"results = []\ni = 0\n\n# Looping through the files in dataset\nfor file in os.listdir(f\"/kaggle/input/{models_dataset}/\"):\n\n    # Filtering files to get only models (not  tokenizers) that are not bad models (unless this is the original model)\n    if \"tok\" != file[:3] and \".obj\" in file and (file not in bad_models or \"original\" in file):\n\n        # Skipping selected few models (code had to be run multiple times as memory resources were unsufficient to explain all models in one go)\n        i+=1\n        if i<= skip and \"original\" not in file: continue\n\n        # Loading the model\n        print(file)\n        with open(f\"/kaggle/input/{models_dataset}/\"+file, 'rb') as pickle_file:\n            model = pickle.load(pickle_file)\n\n            # Using GPU for DistilBERT and loading its tokenizer\n            if file.split(\"_\")[-1].split('.obj')[0]==\"DistilBERT\":\n                model.to(device)\n                tokenizer = test_dataset.tokenizer\n            # Loaidng tokenizers for other models\n            else:\n                with open(f\"/kaggle/input/{models_dataset}/\"+\"tok_\"+file, 'rb') as tok_file:\n                    tokenizer = pickle.load(tok_file) \n\n            # Calculating explanations\n            result = get_xai(0, explain_count, model, tokenizer)\n            results.append([file, result])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:59:52.312610Z","iopub.execute_input":"2025-01-11T22:59:52.313032Z","iopub.status.idle":"2025-01-12T01:02:06.326559Z","shell.execute_reply.started":"2025-01-11T22:59:52.312994Z","shell.execute_reply":"2025-01-12T01:02:06.325789Z"}},"outputs":[{"name":"stdout","text":"erqaser_movie_20_LLama_4_LSTM.obj\neraser_movie_50_Contextual_word_embedding_4_LSTM.obj\nerqaser_movie_50_LLama_1_LSTM.obj\nerqaser_movie_10_LLama_0_LSTM.obj\neraser_movie_50_paraphrase_3_LSTM.obj\nerqaser_movie_50_LLama_3_LSTM.obj\nerqaser_movie_20_LLama_1_LSTM.obj\neraser_movie_20_Contextual_word_embedding_0_LSTM.obj\nerqaser_movie_10_LLama_1_LSTM.obj\nerqaser_movie_20_LLama_complex_3_LSTM.obj\nerqaser_movie_20_LLama_complex_4_LSTM.obj\nerqaser_movie_10_LLama_complex_1_LSTM.obj\neraser_movie_50_Spelling_mistake_2_LSTM.obj\nerqaser_movie_10_LLama_complex_3_LSTM.obj\nerqaser_movie_50_LLama_4_LSTM.obj\nerqaser_movie_50_LLama_complex_3_LSTM.obj\nerqaser_movie_50_LLama_0_LSTM.obj\nerqaser_movie_10_LLama_complex_2_LSTM.obj\nerqaser_movie_10_LLama_3_LSTM.obj\nerqaser_movie_10_LLama_complex_4_LSTM.obj\nerqaser_movie_50_LLama_complex_0_LSTM.obj\neraser_movie_50_paraphrase_1_LSTM.obj\nerqaser_movie_10_LLama_2_LSTM.obj\nerqaser_movie_50_LLama_2_LSTM.obj\neraser_movie_10_ROS_4_LSTM.obj\nerqaser_movie_10_LLama_4_LSTM.obj\nerqaser_movie_20_LLama_complex_0_LSTM.obj\neraser_movie_50_paraphrase_2_LSTM.obj\neraser_movie_50_imbalanced_0_LSTM.obj\neraser_movie_100_original_0_LSTM.obj\neraser_movie_20_ROS_1_LSTM.obj\nerqaser_movie_10_LLama_complex_0_LSTM.obj\nerqaser_movie_50_LLama_complex_2_LSTM.obj\nerqaser_movie_20_LLama_complex_2_LSTM.obj\nerqaser_movie_20_LLama_2_LSTM.obj\nerqaser_movie_20_LLama_0_LSTM.obj\nerqaser_movie_50_LLama_complex_1_LSTM.obj\neraser_movie_10_Contextual_word_embedding_4_LSTM.obj\nerqaser_movie_20_LLama_complex_1_LSTM.obj\nerqaser_movie_50_LLama_complex_4_LSTM.obj\nerqaser_movie_20_LLama_3_LSTM.obj\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Method used to properly order LIME values as it was done in order of words\ndef tokenize_evidence(words, exp):\n    explanations = {k:v for k, v in exp.as_list()}\n    xai_lime = [explanations[word] if word in explanations.keys() else 0  for word in words]\n    return xai_lime\n\n\n# Clearing up the results to anticipated format\nres = []\nfor j in range(len(results)):\n    print(results[j][0])\n    for i in range(explain_count):\n        \n        exp = results[j][1][i]\n        words = [word for word in re.split(r'\\W+',test_dataset.inputs[i]) if word != \"\"]\n        xai_lime = tokenize_evidence(words, exp)\n\n        # Saving results for further analysis\n        explanation = {}\n        explanation[\"model\"] = results[j][0]                                               # Model object name\n        explanation[\"id\"] = i                                                              # Explained instance id\n        explanation[\"words_sentence\"] = words                                              # List of all words in a given instance\n        explanation[\"lime_sentence\"] = xai_lime                                            # Lime values for all words in a given instance\n        explanation[\"words_word\"] = np.unique(words)                                       # List of unique words in a given instance\n        explanation[\"lime_word\"] = tokenize_evidence(explanation[\"words_word\"], exp)       # Lime values for unique words in a given instance\n        res.append(explanation)\n        \npd.DataFrame(res).to_csv(\"XAI_results_final_LSTM.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:02:06.329274Z","iopub.execute_input":"2025-01-12T01:02:06.329549Z","iopub.status.idle":"2025-01-12T01:02:12.039304Z","shell.execute_reply.started":"2025-01-12T01:02:06.329524Z","shell.execute_reply":"2025-01-12T01:02:12.038253Z"}},"outputs":[{"name":"stdout","text":"erqaser_movie_20_LLama_4_LSTM.obj\neraser_movie_50_Contextual_word_embedding_4_LSTM.obj\nerqaser_movie_50_LLama_1_LSTM.obj\nerqaser_movie_10_LLama_0_LSTM.obj\neraser_movie_50_paraphrase_3_LSTM.obj\nerqaser_movie_50_LLama_3_LSTM.obj\nerqaser_movie_20_LLama_1_LSTM.obj\neraser_movie_20_Contextual_word_embedding_0_LSTM.obj\nerqaser_movie_10_LLama_1_LSTM.obj\nerqaser_movie_20_LLama_complex_3_LSTM.obj\nerqaser_movie_20_LLama_complex_4_LSTM.obj\nerqaser_movie_10_LLama_complex_1_LSTM.obj\neraser_movie_50_Spelling_mistake_2_LSTM.obj\nerqaser_movie_10_LLama_complex_3_LSTM.obj\nerqaser_movie_50_LLama_4_LSTM.obj\nerqaser_movie_50_LLama_complex_3_LSTM.obj\nerqaser_movie_50_LLama_0_LSTM.obj\nerqaser_movie_10_LLama_complex_2_LSTM.obj\nerqaser_movie_10_LLama_3_LSTM.obj\nerqaser_movie_10_LLama_complex_4_LSTM.obj\nerqaser_movie_50_LLama_complex_0_LSTM.obj\neraser_movie_50_paraphrase_1_LSTM.obj\nerqaser_movie_10_LLama_2_LSTM.obj\nerqaser_movie_50_LLama_2_LSTM.obj\neraser_movie_10_ROS_4_LSTM.obj\nerqaser_movie_10_LLama_4_LSTM.obj\nerqaser_movie_20_LLama_complex_0_LSTM.obj\neraser_movie_50_paraphrase_2_LSTM.obj\neraser_movie_50_imbalanced_0_LSTM.obj\neraser_movie_100_original_0_LSTM.obj\neraser_movie_20_ROS_1_LSTM.obj\nerqaser_movie_10_LLama_complex_0_LSTM.obj\nerqaser_movie_50_LLama_complex_2_LSTM.obj\nerqaser_movie_20_LLama_complex_2_LSTM.obj\nerqaser_movie_20_LLama_2_LSTM.obj\nerqaser_movie_20_LLama_0_LSTM.obj\nerqaser_movie_50_LLama_complex_1_LSTM.obj\neraser_movie_10_Contextual_word_embedding_4_LSTM.obj\nerqaser_movie_20_LLama_complex_1_LSTM.obj\nerqaser_movie_50_LLama_complex_4_LSTM.obj\nerqaser_movie_20_LLama_3_LSTM.obj\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"3+5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:02:12.040485Z","iopub.execute_input":"2025-01-12T01:02:12.040894Z","iopub.status.idle":"2025-01-12T01:02:12.047623Z","shell.execute_reply.started":"2025-01-12T01:02:12.040863Z","shell.execute_reply":"2025-01-12T01:02:12.046765Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}