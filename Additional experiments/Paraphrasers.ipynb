{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing packages","metadata":{"execution":{"iopub.status.busy":"2024-09-01T08:46:04.464115Z","iopub.execute_input":"2024-09-01T08:46:04.464754Z","iopub.status.idle":"2024-09-01T08:46:04.471279Z","shell.execute_reply.started":"2024-09-01T08:46:04.464702Z","shell.execute_reply":"2024-09-01T08:46:04.469666Z"}}},{"cell_type":"code","source":"!pip install nlp\n!pip install captum\n!pip install bio\n!pip install evaluate\n!pip install bert_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-11T12:31:46.706066Z","iopub.execute_input":"2024-11-11T12:31:46.706526Z","iopub.status.idle":"2024-11-11T12:33:07.587145Z","shell.execute_reply.started":"2024-11-11T12:31:46.706483Z","shell.execute_reply":"2024-11-11T12:33:07.585497Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting nlp\n  Downloading nlp-0.4.0-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from nlp) (1.26.4)\nRequirement already satisfied: pyarrow>=0.16.0 in /opt/conda/lib/python3.10/site-packages (from nlp) (17.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from nlp) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from nlp) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from nlp) (2.32.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from nlp) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from nlp) (3.15.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from nlp) (3.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->nlp) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->nlp) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->nlp) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->nlp) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->nlp) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->nlp) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->nlp) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->nlp) (1.16.0)\nDownloading nlp-0.4.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlp\nSuccessfully installed nlp-0.4.0\nCollecting captum\n  Downloading captum-0.7.0-py3-none-any.whl.metadata (26 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from captum) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from captum) (1.26.4)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from captum) (2.4.0+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from captum) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum) (2024.6.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->captum) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\nDownloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: captum\nSuccessfully installed captum-0.7.0\nCollecting bio\n  Downloading bio-1.7.1-py3-none-any.whl.metadata (5.7 kB)\nCollecting biopython>=1.80 (from bio)\n  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting gprofiler-official (from bio)\n  Downloading gprofiler_official-1.0.0-py3-none-any.whl.metadata (11 kB)\nCollecting mygene (from bio)\n  Downloading mygene-3.2.2-py2.py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from bio) (2.2.3)\nRequirement already satisfied: pooch in /opt/conda/lib/python3.10/site-packages (from bio) (1.8.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bio) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from bio) (4.66.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from biopython>=1.80->bio) (1.26.4)\nCollecting biothings-client>=0.2.6 (from mygene->bio)\n  Downloading biothings_client-0.3.1-py2.py3-none-any.whl.metadata (9.8 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->bio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->bio) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->bio) (2024.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch->bio) (3.11.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pooch->bio) (21.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bio) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bio) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bio) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bio) (2024.8.30)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pooch->bio) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->bio) (1.16.0)\nDownloading bio-1.7.1-py3-none-any.whl (280 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.0/281.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\nDownloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\nDownloading biothings_client-0.3.1-py2.py3-none-any.whl (29 kB)\nInstalling collected packages: biopython, gprofiler-official, biothings-client, mygene, bio\nSuccessfully installed bio-1.7.1 biopython-1.84 biothings-client-0.3.1 gprofiler-official-1.0.0 mygene-3.2.2\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nCollecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.4.0+cpu)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.45.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.25.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.20.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (10.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2024.8.30)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T12:33:07.589762Z","iopub.execute_input":"2024-11-11T12:33:07.590188Z","iopub.status.idle":"2024-11-11T12:33:30.236421Z","shell.execute_reply.started":"2024-11-11T12:33:07.590142Z","shell.execute_reply":"2024-11-11T12:33:30.235021Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git\n  Cloning https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git to /tmp/pip-req-build-3isniy9h\n  Running command git clone --filter=blob:none --quiet https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git /tmp/pip-req-build-3isniy9h\n  Resolved https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git to commit 03084c54b64019ba5fa0b620b9c70ad81123e458\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from parrot==1.0) (4.45.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from parrot==1.0) (0.2.0)\nCollecting python-Levenshtein (from parrot==1.0)\n  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\nCollecting sentence-transformers (from parrot==1.0)\n  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: fuzzywuzzy in /opt/conda/lib/python3.10/site-packages (from parrot==1.0) (0.18.0)\nCollecting Levenshtein==0.26.1 (from python-Levenshtein->parrot==1.0)\n  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein->parrot==1.0)\n  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->parrot==1.0) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->parrot==1.0) (2.4.0+cpu)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->parrot==1.0) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->parrot==1.0) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->parrot==1.0) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->parrot==1.0) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->parrot==1.0) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->parrot==1.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->parrot==1.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->parrot==1.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->parrot==1.0) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->parrot==1.0) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->parrot==1.0) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->parrot==1.0) (0.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers->parrot==1.0) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers->parrot==1.0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->parrot==1.0) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->parrot==1.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->parrot==1.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->parrot==1.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->parrot==1.0) (2024.8.30)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->parrot==1.0) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->parrot==1.0) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers->parrot==1.0) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers->parrot==1.0) (1.3.0)\nDownloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\nDownloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading sentence_transformers-3.3.0-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.7/268.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: parrot\n  Building wheel for parrot (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for parrot: filename=parrot-1.0-py3-none-any.whl size=8590 sha256=2339a96202424bcf8b7555c391fcc2b2b930d2496b7408456335033f057241f0\n  Stored in directory: /tmp/pip-ephem-wheel-cache-k06mxjr5/wheels/e8/ee/2a/4d6a4b2a5c37f5f750e90fa79d2ad84f444fba9b050ecbbe6d\nSuccessfully built parrot\nInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein, sentence-transformers, parrot\nSuccessfully installed Levenshtein-0.26.1 parrot-1.0 python-Levenshtein-0.26.1 rapidfuzz-3.10.1 sentence-transformers-3.3.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\nfrom typing import Dict\n\n# Basic imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport time\n\n\n# NLP related libraries\nimport nlp\nimport torch\nfrom torch.utils.data import Dataset\nimport transformers\nfrom transformers import (ElectraForSequenceClassification,\n                          ElectraTokenizerFast, EvalPrediction, InputFeatures,\n                          Trainer, TrainingArguments, glue_compute_metrics, pipeline,\n                         AutoTokenizer, AutoModelForSequenceClassification,\n                         T5ForConditionalGeneration, T5TokenizerFast,\n                         BartTokenizer, BartForConditionalGeneration,\n                         AutoModelForSeq2SeqLM)\n\n# XAI\nfrom captum.attr import (IntegratedGradients, LayerIntegratedGradients,\n                         configure_interpretable_embedding_layer,\n                         remove_interpretable_embedding_layer)\nfrom captum.attr import visualization as viz\n\n# Alignment\nfrom Bio import pairwise2\nfrom Bio.pairwise2 import format_alignment\n\n# BERT score\nfrom evaluate import load\n\n# Supressing warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom parrot import Parrot\n\ntransformers.__version__","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:33:30.238189Z","iopub.execute_input":"2024-11-11T12:33:30.238573Z","iopub.status.idle":"2024-11-11T12:33:57.792052Z","shell.execute_reply.started":"2024-11-11T12:33:30.238532Z","shell.execute_reply":"2024-11-11T12:33:57.790809Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'4.45.1'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"\ntrain_dataset = nlp.load_dataset('imdb', split='train')","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:33:57.794767Z","iopub.execute_input":"2024-11-11T12:33:57.795513Z","iopub.status.idle":"2024-11-11T12:35:11.306026Z","shell.execute_reply.started":"2024-11-11T12:33:57.795462Z","shell.execute_reply":"2024-11-11T12:35:11.304793Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfb4b22ff4a4420a99466f2f5d2cd0ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c57ef4aa13a74ef3b349174517d1e325"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.06 MiB, post-processed: Unknown sizetotal: 207.28 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/76cdbd7249ea3548c928bbf304258dab44d09cd3638d9da8d42480d1d1be3743...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/84.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d15091b11c804899967946bba4b90b13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a87f1fe2ca0d4613a8fc8e5a8eefede4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d34ea2e3cbb647b58212f6f2ab0f7ec1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa2a8b896b764c29a95ae98fb14d1ac7"}},"metadata":{}},{"name":"stdout","text":"Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/76cdbd7249ea3548c928bbf304258dab44d09cd3638d9da8d42480d1d1be3743. Subsequent calls will reuse this data.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:35:11.307829Z","iopub.execute_input":"2024-11-11T12:35:11.308777Z","iopub.status.idle":"2024-11-11T12:35:11.317528Z","shell.execute_reply.started":"2024-11-11T12:35:11.308731Z","shell.execute_reply":"2024-11-11T12:35:11.313610Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:35:11.319597Z","iopub.execute_input":"2024-11-11T12:35:11.320456Z","iopub.status.idle":"2024-11-11T12:35:14.038147Z","shell.execute_reply.started":"2024-11-11T12:35:11.320380Z","shell.execute_reply":"2024-11-11T12:35:14.037000Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0f0c6481aa9484ab9e6191337cd6e6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4452ff23836a4af185eaa6706c5be6ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1f9bd2101e44df89d896092a98d3cc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9a89a1db1a242e183585ece0c6bd1b0"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"\nclass TrainerDataset(Dataset):\n    def __init__(self, inputs, targets, tokenizer):\n        self.inputs = inputs\n        self.targets = targets\n        self.tokenizer = tokenizer\n\n        # Tokenize the input\n        self.tokenized_inputs = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")   \n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return InputFeatures(\n            input_ids=self.tokenized_inputs['input_ids'][idx],\n#             token_type_ids=self.tokenized_inputs['token_type_ids'][idx],\n            attention_mask=self.tokenized_inputs['attention_mask'][idx],\n            label=self.targets[idx])   ","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:35:14.039485Z","iopub.execute_input":"2024-11-11T12:35:14.039843Z","iopub.status.idle":"2024-11-11T12:35:14.048843Z","shell.execute_reply.started":"2024-11-11T12:35:14.039806Z","shell.execute_reply":"2024-11-11T12:35:14.047360Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset = TrainerDataset(train_dataset[\"text\"],\n                               train_dataset[\"label\"], tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:35:14.050300Z","iopub.execute_input":"2024-11-11T12:35:14.050786Z","iopub.status.idle":"2024-11-11T12:35:37.209814Z","shell.execute_reply.started":"2024-11-11T12:35:14.050733Z","shell.execute_reply":"2024-11-11T12:35:37.208599Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"a = [1, 2, 3,4]\nb = [\"a\", \"b\", \"c\",\"d\"]\nnp.random.seed(123)\nnp.random.shuffle(a)\nnp.random.seed(123)\nnp.random.shuffle(b)\na,b","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:35:37.211268Z","iopub.execute_input":"2024-11-11T12:35:37.211675Z","iopub.status.idle":"2024-11-11T12:35:37.221256Z","shell.execute_reply.started":"2024-11-11T12:35:37.211625Z","shell.execute_reply":"2024-11-11T12:35:37.220210Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"([4, 1, 2, 3], ['d', 'a', 'b', 'c'])"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# Alignment measures","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:56:40.087488Z","iopub.execute_input":"2024-10-27T09:56:40.087879Z","iopub.status.idle":"2024-10-27T09:56:40.092182Z","shell.execute_reply.started":"2024-10-27T09:56:40.087840Z","shell.execute_reply":"2024-10-27T09:56:40.091260Z"}}},{"cell_type":"code","source":"\n\n\nstring1 = 'my channel is youtube dot com slash example and then I also do live streaming on twitch.'\nstring2 = 'my channel is youtube.com/example and then I also do livestreaming on twitch.'\n\nalignments = pairwise2.align.globalxx(string1.split(), \n                                      string2.split(),\n                                      gap_char=['-']\n                                     )\nprint(format_alignment(*alignments[0]))\n\nalignments2 = pairwise2.align.globalxx(string1.split(), \n                                      string1.split(),\n                                      gap_char=['-']\n                                     )\nprint(format_alignment(*alignments2[0]))\nprint(f\"Score: {alignments[0].score/alignments2[0].score}\") #<- less is btter\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:35:37.225486Z","iopub.execute_input":"2024-11-11T12:35:37.225937Z","iopub.status.idle":"2024-11-11T12:35:37.350406Z","shell.execute_reply.started":"2024-11-11T12:35:37.225890Z","shell.execute_reply":"2024-11-11T12:35:37.349069Z"},"trusted":true},"outputs":[{"name":"stdout","text":"my channel is youtube dot com slash example          -          and then I also do live streaming       -       on twitch. \n |    |     |                                                    |    |  |   |   |                               |    |    \nmy channel is    -     -   -    -      -    youtube.com/example and then I also do  -       -     livestreaming on twitch. \n  Score=10\n\nmy channel is youtube dot com slash example and then I also do live streaming on twitch. \n |    |     |    |     |   |    |      |     |    |  |   |   |   |      |      |    |    \nmy channel is youtube dot com slash example and then I also do live streaming on twitch. \n  Score=17\n\nScore: 0.5882352941176471\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# BERT Score","metadata":{}},{"cell_type":"code","source":"\nbertscore = load(\"bertscore\")\npredictions = [\"hello there\", \"general kenobi\"]\nreferences = [\"goodbye here\", \"admiral skywalker\"]\nresults = bertscore.compute(predictions=predictions, references=references, lang=\"en\", model_type=\"distilbert-base-uncased\", verbose=0)\nresults","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:35:37.352118Z","iopub.execute_input":"2024-11-11T12:35:37.352588Z","iopub.status.idle":"2024-11-11T12:35:43.741012Z","shell.execute_reply.started":"2024-11-11T12:35:37.352545Z","shell.execute_reply":"2024-11-11T12:35:43.740000Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e5ad0545e4742ef85527caa8df4cc45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e8a3913f1b141c4a3fa8648d571d9cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf449abce7a34499a577659032318814"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68d189da50074d9b953bc318077e0f32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e661db23f824bfdb8d0224a2c3d62cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce828f7495ab4160a6f13de5dd4fed44"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'precision': [0.8584095239639282, 0.6368807554244995],\n 'recall': [0.8584095239639282, 0.6684491634368896],\n 'f1': [0.8584095239639282, 0.652283251285553],\n 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.45.1)'}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"positives = np.array(train_dataset.inputs)[np.array(train_dataset.targets)==1]\nn_positive = len(positives)\nsentences = str(positives[np.random.randint(n_positive)])\n\nparrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\", use_gpu=False)\nfrom transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer, AutoModelForSeq2SeqLM\n\nfrom transformers import AutoTokenizer, BigBirdPegasusModel\nimport torch\nfrom transformers import PegasusTokenizer, PegasusForConditionalGeneration\nimport re\n\ntokenizer_bigbird = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\nparaphraser_bigbird = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n\ntokenizer_pegasus = PegasusTokenizer.from_pretrained(\"tuner007/pegasus_paraphrase\")\nparaphraser_pegasus = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\n\nparaphraser_t5small = T5ForConditionalGeneration.from_pretrained(\"mrm8488/t5-small-finetuned-quora-for-paraphrasing\")\ntokenizer_t5small = T5TokenizerFast.from_pretrained(\"mrm8488/t5-small-finetuned-quora-for-paraphrasing\")\n\nparaphraser_t5 = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\ntokenizer_t5 = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n\ntokenizer_bert = BartTokenizer.from_pretrained('facebook/bart-base')\nparaphraser_bert = BartForConditionalGeneration.from_pretrained('facebook/bart-base')","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:35:43.742554Z","iopub.execute_input":"2024-11-11T12:35:43.743003Z","iopub.status.idle":"2024-11-11T12:39:30.015039Z","shell.execute_reply.started":"2024-11-11T12:35:43.742961Z","shell.execute_reply":"2024-11-11T12:39:30.013104Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.89k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f1c574a4167481183930c6293ee9a0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbd1de70bf854fc2b14433218b69177c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f40e7edd30a4254894cea66d55731ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b04dd6e592cc42a5b021d9b151d60390"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"757575b879e44ac2bde948b1e4c0072d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/913 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fafad5b9e55149119dbf3db16fe4850e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26bee276cb08471fba95566bc3d0a2f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f61ab8e92da4f1da021fab3f08f6d81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2bec75c8b49470f908296408acf478a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b0c73dd1bf849f4b0fb3cc63b851844"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa8c5260241d4eb2892038113e16c4e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/476 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"509d71876ac94fad8c8b6ad431444071"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ba9b1d7d0c740d5952f4c2a9d3bcec7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba7e9d68dbde44b5a861a88e01cd880b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db0a472ad0244c01bab4e80f4e9e3a8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b1649297b9b45b8a32ec9c4793f4c8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbee6f9dbaf042169531440579bd9410"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d130d8b6f2647fe95b58364bb53909b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.78k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ca006ef23924a2798357be603fc18d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70974e1f827847818e23ad184f02f9b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/686 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c323784733a4d469b67f6ca8f0317e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7f80f8b743c48c5888d29aaf98a4560"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d945c16927848d19cc046540962566c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"217fcb581abd487794ae0ca29c79c0fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820201e284d24822856c7d278939bfd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c146a70522a3439387f94ef3406b1c1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8e7ce482c754521b25a064869ebb38a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"037dd5a6c00b425a940bc537f63bdf2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"090f369564e84077b9b05e4d2fb6a0f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b75584fb96b04f35aa3541154475dac8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.92M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a512b19e947f405db5a6261e40c1b253"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.51M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab1999d7ace949479deb71c703d0cf31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/775 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfdd64ed2977412cbeea989394aaff36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.31G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f03b8ac01f4b49eea03aa98b1e83fe53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/232 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5257892933d6432bac2494591f82ba2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/86.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a002c86841d4636b1656f6d1e7b43ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c4732f09ef9460398e0ce4e88dd38f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c502f216bde493ba1b879487bea02cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf4e4d66e1124b55b518bf52aee01148"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5896e283c1e486fb0312a40fcec4837"}},"metadata":{}},{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b284f27258dd419992ab82bee1153b00"}},"metadata":{}},{"name":"stderr","text":"The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d036edb278a14938addb3324ff5c0465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec9af47b3fd9494e9c014c22de1a938d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d25805b59c4e8e8911a90f5dff56a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e09e195eafde465d9301463986cef666"}},"metadata":{}},{"name":"stderr","text":"The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b4dcbf3ab2b4d7bace2d9ed3e3888e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5e00482ec31468ea2627bdf69499d18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b6b22c8e11b49fc8e51d24b1be6021a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6da75b1e7fd549dfb3ac5018891c5289"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"726883df171d4732bc01aa60d5f13c9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"943721f6853246b4bd93cc9277533ff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455d8788df2b42d5b69932af32474f49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca6833a7f8d0447f9e64127df48c70f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31bb186e123c4ca0beb21fdbf9e056de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07717a18efd24f938e2efcf4878bb6a9"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"\ntokenizer = PegasusTokenizer.from_pretrained(\"tuner007/pegasus_paraphrase\")\nparaphraser = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\n\n# input sentences\npositives = np.array(train_dataset.inputs)[np.array(train_dataset.targets)==1]\nn_positive = len(positives)\nsentences = str(positives[np.random.randint(n_positive)])\nprint(sentences,end=\"\\n\\n\\n\")\n\ndef paraphrase(sentences, paraphraser, tokenizer, cat = False):\n    # Paraphrase the sentences. Reviews are too long it's best to paraphrase one sentence at a time\n    output = []\n    reference = re.split(r'[.?!]', sentences)\n    for sentence in reference:\n        if len(sentence)>0 :\n\n            # Tokenize the input sentence\n            input_ids = tokenizer.encode(sentence, return_tensors='pt')\n\n            if len(input_ids[0])>=50:\n                output.append(sentence)\n                continue\n                \n            # Generate paraphrased sentence\n            paraphrase_ids = paraphraser.generate(input_ids, num_beams=5, max_length=1024, early_stopping=True, no_repeat_ngram_size=3)\n        \n            # Decode and print the paraphrased sentence\n            paraphrase = tokenizer.decode(paraphrase_ids[0], skip_special_tokens=True, verbose=0)\n            if cat:\n                print(f\"Original: {sentence}\")\n                print(f\"Paraphrase: {paraphrase}\")\n                print()\n            output.append(paraphrase)\n        else:\n            output.append(sentence)\n    return output, reference\n\n\ndef paraphrase_parrot(sentences,cat=False):\n    # Paraphrase the sentences. Reviews are too long it's best to paraphrase one sentence at a time\n    output = []\n    reference = re.split(r'[.?!]', sentences)\n    for sentence in reference:\n        if len(sentence)>0 :\n\n            if len(sentence)>=100:\n                output.append(sentence)\n                continue\n                \n            # Generate paraphrased sentence\n            paraphrase = parrot.augment(input_phrase=sentence)\n            if paraphrase==None:\n                paraphrase = sentence\n            else:\n                paraphrase, _ = paraphrase[0]\n            output.append(paraphrase)\n            if cat:\n                print(f\"Original: {sentence}\")\n                print(f\"Paraphrase: {paraphrase}\")\n                print()\n            \n        else:\n            output.append(sentence)\n    return output, reference\n\n\ndef paraphrase_bigbird(sentences,cat=False):\n    # Paraphrase the sentences. Reviews are too long it's best to paraphrase one sentence at a time\n    output = []\n\n    if len(sentences)>0 :\n        input_ids = tokenizer_bigbird.encode(sentences, return_tensors='pt')\n            \n        # Generate paraphrased sentence\n        paraphrase_ids = paraphraser_bigbird.generate(input_ids)\n        \n        output = tokenizer_bigbird.decode(paraphrase_ids[0], skip_special_tokens=True, verbose=0)\n        \n        if cat:\n            print(f\"Original: {sentences}\")\n            print(f\"Paraphrase: {output}\")\n            print()\n        \n    \n    return output, sentences\n\n\n# output, reference = paraphrase(sentences, paraphraser, tokenizer, True)","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:39:30.018789Z","iopub.execute_input":"2024-11-11T12:39:30.019416Z","iopub.status.idle":"2024-11-11T12:39:35.112795Z","shell.execute_reply.started":"2024-11-11T12:39:30.019338Z","shell.execute_reply":"2024-11-11T12:39:35.110983Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Three horror stories based on members of a transgressive Hindu cult that return home but changed in some way. In the first story our former cult member is now in an insane asylum and is visited by a reported who wants to find out about what went on at the cult. Somewhat slow going as story is told in flashbacks while the two sit on chairs and face each other. Reporter is particularly interested in what lead to the death of the participants. What seemed rather boring suddenly turns very exciting with a surprising twist in the story. Things get quite bloody.<br /><br />Second story has a violent young criminal visiting a psychiatrist for mandatory therapy. The patient seems to have some type of agenda but the psychiatrist is up to the task. Again, things slow down a bit and get weird. Then there's a strange twist in the story that is very well written and surprising.<br /><br />Final story deals with spiritual healer who claims to be able to remove the persons illness from them with his hands. One of the patients is a former cult member, so the successful healing gets more complicated. Again, we are surprised by a twist. Has a pretty gory scene in there.<br /><br />There some nice female full frontal nudity as well as male full frontal nudity for some reason. I found the stories to be very well written and the director succeeds entirely in setting up each story with its surprising twist and the gory aftermath.<br /><br />Note: review of the German DVD.\n\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"\n\ndef evaluate_paraphrase(sentences, paraphraser, tokenizer, name):\n    \n    start = time.time()\n    if name ==  \"bigbird\":\n        \n        output, reference = paraphrase_bigbird(sentences)\n    elif name == \"parrot\":\n        output, reference = paraphrase_parrot(sentences)\n    else:\n        \n        output, reference = paraphrase(sentences, paraphraser, tokenizer, False)\n    time_stat = time.time()-start\n\n\n    \n\n    if name ==  \"bigbird\":\n        output_cleaned = [output]\n        reference_cleaned = [reference]\n        alignment_score =  0\n    else:\n        # Remove empty sentences\n        output_cleaned = []\n        reference_cleaned = []\n        alignment_score = []\n        for i in range(len(reference)):\n            if len(reference[i])!=0 and reference[i]!=\" \" and len(output[i])!=0 and output[i]!=\" \":\n                output_cleaned.append(output[i])\n                reference_cleaned.append(reference[i])\n                alignments = pairwise2.align.globalxx(reference[i].split(), \n                                              output[i].split(),\n                                              gap_char=['-']\n                                             )\n    \n    \n                alignments2 = pairwise2.align.globalxx(reference[i].split(), \n                                                      reference[i].split(),\n                                                      gap_char=['-']\n                                                     )\n                alignment_score.append(alignments[0].score/alignments2[0].score)\n\n\n\n\n    results = bertscore.compute(predictions=output_cleaned, references=reference_cleaned, lang=\"en\", model_type=\"distilbert-base-uncased\", verbose=0)\n\n    measures = {\"paraphraser\": name,\n                \"time\":time_stat,\n                \"avg alignment\": np.mean(alignment_score)}\n    for k,v in results.items():\n        if k != 'hashcode':\n            measures[\"avg BERT Score \"+ k]=np.mean(v)\n            \n    result = \" \".join(output)\n    \n    alignments = pairwise2.align.globalxx(sentences.split(), \n                                          result.split(),\n                                          gap_char=['-']\n                                         )\n\n\n    alignments2 = pairwise2.align.globalxx(sentences.split(), \n                                          sentences.split(),\n                                          gap_char=['-']\n                                         )\n\n    measures[\"entire sentence alignment\"]=(alignments[0].score/alignments2[0].score)\n    results = bertscore.compute(predictions=[result], references=[sentences], lang=\"en\", model_type=\"distilbert-base-uncased\", verbose=0)\n    for k,v in results.items():\n        if k != 'hashcode':\n            measures[\"entire sentence BERT Score \"+ k]=v[0]\n            \n    measures[\"sentence\"] = sentences\n    measures[\"paraphrase\"] = result\n    \n    \n    return measures\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T12:39:35.114499Z","iopub.execute_input":"2024-11-11T12:39:35.114942Z","iopub.status.idle":"2024-11-11T12:39:35.137533Z","shell.execute_reply.started":"2024-11-11T12:39:35.114897Z","shell.execute_reply":"2024-11-11T12:39:35.136223Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"np.random.seed(123)\nresults = []\nfor sentences in [str(positives[np.random.randint(n_positive)]) for _ in range(30)]:\n    for paraphraser, tokenizer, name in [(None, None, \"bigbird\"),\n                                         (paraphraser_pegasus, tokenizer_pegasus, \"Pegasus\"),\n                                         (paraphraser_t5small, tokenizer_t5small, \"t5-small\"),\n                                         (paraphraser_t5, tokenizer_t5, \"t5\"),\n                                         (paraphraser_bert, tokenizer_bert, \"BERT\"),\n                                        (None, None, \"parrot\")\n                                         \n                                        ]:\n        results.append(evaluate_paraphrase(sentences, paraphraser, tokenizer, name))\nres = pd.DataFrame(results)\n\ndef highlight_max(s, props=''):\n    return np.where(s == np.nanmax(s.values ), props, '')\n\ndef highlight_min(s, props=''):\n    return np.where(s == np.nanmin(s.values), props, '')\n(\nresults.tail(10).style.apply(highlight_max, axis=0, props='background-color:green;', subset=[\"avg BERT Score precision\", \"avg BERT Score recall\", \"avg BERT Score f1\", \"entire sentence BERT Score precision\", \"entire sentence BERT Score recall\", \"entire sentence BERT Score f1\"])\n         .apply(highlight_min, axis=0, props='background-color:green;', subset=['time', 'avg alignment', \"entire sentence alignment\"])\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T12:39:35.141523Z","iopub.execute_input":"2024-11-11T12:39:35.142816Z","iopub.status.idle":"2024-11-11T13:03:11.520148Z","shell.execute_reply.started":"2024-11-11T12:39:35.142748Z","shell.execute_reply":"2024-11-11T13:03:11.437375Z"}},"outputs":[{"name":"stderr","text":"Attention type 'block_sparse' is not possible if sequence_length: 413 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n","output_type":"stream"},{"name":"stdout","text":"[('first comments on this movie were so vicious that i had to go see for myself', 16), ('first comments on this movie were so vicious that i had to see it for myself', 16), ('the first comments made on this movie were so vicious that i had to see for myself', 15), ('the first comments on this film were so vicious that i had to see for myself', 15), ('the first comments on this movie were so vicious that i had to see for myself', 10)]\n[(' Michael Caton-Jones is not Paul Verhoeven, neither Henry Bean and Leora Barish are Joe Eszterhas', 0)]\n[('unfortunately she seems to be the main target for those who like to trash this movie', 27), ('unfortunately she seems to be the main target for those who like to trash this film', 25), ('unfortunately she appears to be the main target for those who enjoy trashing this flick', 18), ('unfortunately she seems to be the main target for those who enjoy trashing this movie', 18), ('unfortunately she seems to be the main target for those who enjoy trashing this flick', 13)]\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (89 > 60). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"[('this is a serious work whose unjust reputation needs to be restored and its reputation restored', 68), ('this is a serious work whose unjust reputation deserves rediscovery and restoration', 65), ('this is a serious work which merits the rediscovery and restoration of its unjustly tarnished reputation', 27), ('this is a serious job requiring the discovery and restoration of its unjustly tarnished reputation', 24), (\"it's a serious work requiring rediscovery and restoration of its unjustly tarnished reputation\", 23), ('this is a serious work which deserves rediscovery and restoration of its unjustly tarnished reputation', 22), ('this is a serious work that deserves rediscovery and restoration of its unjustly tarnished reputation', 21), ('this is a serious work deserving of rediscovery and restoration of its unjustly tarnished reputation', 16)]\n[('the gorilla looks tremendous and the eyes were extremely realistic', 40), ('the gorilla looks fantastic and the eyes were particularly real', 38), ('the gorilla looks absolutely brilliant and the eyes were especially real', 34), ('the gorilla looks fantastic and the eyes were particularly lifelike', 31), ('the gorilla looks very splendid and the eyes were really lifelike', 29)]\n[('rene russo plays a wonderful feminine role', 28)]\n[(' Somewhat slow going as story is told in flashbacks while the two sit on chairs and face each other', 0)]\n[('reporter is particularly interested in the circumstances that led to the death of the participants', 33), ('the journalist is particularly interested in what caused the death of the participants', 25), ('the reporter is particularly interested in the factors that led to the death of the participants', 24), ('the journalist is particularly interested in what led to the death of the participants', 20), ('reporter is particularly interested in what led to the death of participants', 18), ('the reporter is particularly interested in what led to the death of participants', 15), ('reporter is particularly interested in what led to the death of the participants', 14)]\n[('what seemed rather boring suddenly becomes extremely exciting with a surprising twist in the story', 26), ('what seemed rather boring suddenly becomes very exciting with a surprising twist in the story', 19)]\n[('it gets rather bloody', 24), ('it gets bloody', 24), ('things get really bloody', 19), ('some things can become bloody', 19)]\n[('a violent young criminal goes to a psychiatrist for mandatory therapy', 44), ('another story about a violent young criminal visiting a psychiatrist for mandatory therapy', 27), ('the second story is about a violent young criminal visiting a psychiatrist for mandatory therapy', 24), ('this second story has a violent young criminal visiting a psychiatrist for mandatory therapy', 17), ('the second story has a violent young criminal visiting a psychiatrist for mandatory therapy', 17), ('br br  second story has a violent young criminal visiting a psychiatrist for mandatory therapy', 14), ('br br second story has a violent young criminal visiting a psychiatrist for mandatory therapy', 14)]\n[('the patient seems to have some sort of agenda but the psychiatrist is capable of doing so', 32), ('the patient appears to have some kind of agenda but the psychiatrist is up to the task', 22), ('the patient seems to have some sort of agenda but the psychiatrist is up to the task', 17), ('the patient seems to have some kind of agenda but the psychiatrist is up to the task', 17)]\n[('again things slow down a little and then it gets weird', 26), ('again things slow down and it gets weird', 21), ('again things slow down and go weird', 21), ('once again things slow down and get weird', 17), ('again things slow down a little and get weird', 17), ('again things slow down a bit and get weird', 13)]\n[(\"there's then a strange twist in the story which is very well written and quite surprising\", 28), (\"there's a strange twist in the story that's well written and surprising\", 25), (\"then there's a strange twist in the story that is well written and surprising\", 18)]\n[('one of the patients is a former cult member so healing becomes more complicated', 33), ('one of the patients is a former member of a cult so the successful healing gets more complicated', 28), ('one of the patients is a former cult member so the successful healing becomes more complicated', 18), ('one of the patients is a former cult member so the successful healing gets more complicated', 13)]\n[(\"we're surprised again by a twist\", 27)]\n[(\"there's a pretty frightful scene there\", 24), (\"there's a pretty gory scene in there\", 13)]\n[('note a review of the german dvd', 22)]\n[('no director i like more than mamoru oshii', 21)]\n[(' Go figure', 0)]\n[('<br /><br />At its very core lies a documentary not quite unlike Otaku no Video', 0)]\n[(' Deadpan humor taken to the extreme', 0)]\nNone\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentences \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mstr\u001b[39m(positives[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(n_positive)]) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m)]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m paraphraser, tokenizer, name \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigbird\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m                                          (paraphraser_pegasus, tokenizer_pegasus, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPegasus\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m                                          (paraphraser_t5small, tokenizer_t5small, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                                          \n\u001b[1;32m     11\u001b[0m                                         ]:\n\u001b[0;32m---> 12\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mevaluate_paraphrase\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparaphraser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhighlight_max\u001b[39m(s, props\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","Cell \u001b[0;32mIn[14], line 8\u001b[0m, in \u001b[0;36mevaluate_paraphrase\u001b[0;34m(sentences, paraphraser, tokenizer, name)\u001b[0m\n\u001b[1;32m      6\u001b[0m     output, reference \u001b[38;5;241m=\u001b[39m paraphrase_bigbird(sentences)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparrot\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     output, reference \u001b[38;5;241m=\u001b[39m \u001b[43mparaphrase_parrot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     output, reference \u001b[38;5;241m=\u001b[39m paraphrase(sentences, paraphraser, tokenizer, \u001b[38;5;28;01mFalse\u001b[39;00m)\n","Cell \u001b[0;32mIn[13], line 53\u001b[0m, in \u001b[0;36mparaphrase_parrot\u001b[0;34m(sentences, cat)\u001b[0m\n\u001b[1;32m     51\u001b[0m paraphrase \u001b[38;5;241m=\u001b[39m parrot\u001b[38;5;241m.\u001b[39maugment(input_phrase\u001b[38;5;241m=\u001b[39msentence)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(paraphrase)\n\u001b[0;32m---> 53\u001b[0m paraphrase, _ \u001b[38;5;241m=\u001b[39m \u001b[43mparaphrase\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     54\u001b[0m output\u001b[38;5;241m.\u001b[39mappend(paraphrase)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cat:\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"],"ename":"TypeError","evalue":"'NoneType' object is not subscriptable","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"res = pd.DataFrame(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:03:11.521729Z","iopub.status.idle":"2024-11-11T13:03:11.522230Z","shell.execute_reply.started":"2024-11-11T13:03:11.522005Z","shell.execute_reply":"2024-11-11T13:03:11.522029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"res","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:03:11.525308Z","iopub.status.idle":"2024-11-11T13:03:11.526022Z","shell.execute_reply.started":"2024-11-11T13:03:11.525670Z","shell.execute_reply":"2024-11-11T13:03:11.525722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nfor measure in res.columns:\n    if measure in [\"paraphraser\", \"sentence\", \"paraphrase\"]:\n        continue\n    plt.figure(figsize=(8, 5))\n    for par in np.unique(res.paraphraser):\n        df = res[res.paraphraser==par][measure]\n        sns.kdeplot(df, label=par)\n    plt.legend()\n    plt.title(measure)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:03:11.528471Z","iopub.status.idle":"2024-11-11T13:03:11.529129Z","shell.execute_reply.started":"2024-11-11T13:03:11.528811Z","shell.execute_reply":"2024-11-11T13:03:11.528845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_time(time):\n    result = \"\"\n    if time//3600 > 0:\n        result += str(int(time//3600)) + \" h  \"\n        time %= 3600\n    if time//60 > 0:\n        result += str(int(time//60)) + \" m  \"\n        time %= 60\n    if time//1 > 0:\n        result += str(np.round(time,2)) + \" s  \"\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:03:11.531174Z","iopub.status.idle":"2024-11-11T13:03:11.531828Z","shell.execute_reply.started":"2024-11-11T13:03:11.531483Z","shell.execute_reply":"2024-11-11T13:03:11.531515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for par in np.unique(res.paraphraser):\n    text = f\"Average time {par}:\"\n    for _ in range(25-len(text)):\n        text += \" \"\n        \n    print(text+f\"{get_time(np.mean(res[res.paraphraser==par]['time']))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:03:11.534045Z","iopub.status.idle":"2024-11-11T13:03:11.534659Z","shell.execute_reply.started":"2024-11-11T13:03:11.534343Z","shell.execute_reply":"2024-11-11T13:03:11.534376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for par in np.unique(res.paraphraser):\n    text = f\"Average time {par}:\"\n    for _ in range(25-len(text)):\n        text += \" \"\n        \n    print(text+f\"{get_time(np.mean(res[res.paraphraser==par]['time'])*9500)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:03:11.537102Z","iopub.status.idle":"2024-11-11T13:03:11.537737Z","shell.execute_reply.started":"2024-11-11T13:03:11.537396Z","shell.execute_reply":"2024-11-11T13:03:11.537427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}